{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz1xM_wSu030"
      },
      "source": [
        "# 1 Analyse des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAMxk1SjuyGN"
      },
      "source": [
        "a) Charger la base de données digits disponible sous sklearn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OaTZKaZYmp1_"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_digits\n",
        "\n",
        "# Get dataset\n",
        "digits = load_digits()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbUS_8WTvGua",
        "outputId": "68102c20-8e6b-428f-ed4e-8db151ba539a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1797, 64)\n",
            "(1797,)\n"
          ]
        }
      ],
      "source": [
        "# Retrieve the images data in X and the labels in y\n",
        "X = digits.data\n",
        "y = digits.target\n",
        "\n",
        "# Print the dimensions of the images data and the labels\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2pNbG2HvsYJ",
        "outputId": "313aa05e-6c25-42ed-ea55-92f9bf36f56a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class 0 : 178 examples\n",
            "Class 1 : 182 examples\n",
            "Class 2 : 177 examples\n",
            "Class 3 : 183 examples\n",
            "Class 4 : 181 examples\n",
            "Class 5 : 182 examples\n",
            "Class 6 : 181 examples\n",
            "Class 7 : 179 examples\n",
            "Class 8 : 174 examples\n",
            "Class 9 : 180 examples\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Count the number of examples for each class in y\n",
        "counts = Counter(y)\n",
        "\n",
        "# Display the number of examples for each class\n",
        "for label, count in counts.items():\n",
        "  print(\"Class \" + str(label) + \" : \" + str(count) + \" examples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWiSZ_2Iwhg0"
      },
      "source": [
        "b) Séparer une fois pour toutes la base initiale en deux : apprentissage (70%) et test (30%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lm-lFNI9wjQn"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rQskDY64wycZ"
      },
      "source": [
        "# 2 Apprentissage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AfTbqPVxCCE",
        "outputId": "f5ac3c74-15fb-43cb-b329-8d9a2c078ee4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.24696692\n",
            "Iteration 2, loss = 2.08734453\n",
            "Iteration 3, loss = 2.03322571\n",
            "Iteration 4, loss = 1.97306362\n",
            "Iteration 5, loss = 2.02580798\n",
            "Iteration 6, loss = 1.93008665\n",
            "Iteration 7, loss = 1.97283571\n",
            "Iteration 8, loss = 1.93409902\n",
            "Iteration 9, loss = 1.95815752\n",
            "Iteration 10, loss = 1.92951003\n",
            "Iteration 11, loss = 1.96456923\n",
            "Iteration 12, loss = 1.94605551\n",
            "Iteration 13, loss = 1.96052387\n",
            "Iteration 14, loss = 1.94172950\n",
            "Iteration 15, loss = 1.93537152\n",
            "Iteration 16, loss = 1.96741867\n",
            "Iteration 17, loss = 1.93457398\n",
            "Iteration 18, loss = 1.91089416\n",
            "Iteration 19, loss = 1.92200459\n",
            "Iteration 20, loss = 1.88940948\n",
            "Iteration 21, loss = 1.91360357\n",
            "Iteration 22, loss = 1.92232897\n",
            "Iteration 23, loss = 1.89680027\n",
            "Iteration 24, loss = 1.87915400\n",
            "Iteration 25, loss = 1.87659317\n",
            "Iteration 26, loss = 1.84890636\n",
            "Iteration 27, loss = 1.87095451\n",
            "Iteration 28, loss = 1.86321158\n",
            "Iteration 29, loss = 1.89570880\n",
            "Iteration 30, loss = 1.89841888\n",
            "Iteration 31, loss = 1.90280425\n",
            "Iteration 32, loss = 1.87937834\n",
            "Iteration 33, loss = 1.85072536\n",
            "Iteration 34, loss = 1.87926400\n",
            "Iteration 35, loss = 1.88970129\n",
            "Iteration 36, loss = 1.83416641\n",
            "Iteration 37, loss = 1.88772607\n",
            "Iteration 38, loss = 1.66059752\n",
            "Iteration 39, loss = 1.59700044\n",
            "Iteration 40, loss = 1.58906799\n",
            "Iteration 41, loss = 1.54878219\n",
            "Iteration 42, loss = 1.60164648\n",
            "Iteration 43, loss = 1.54840269\n",
            "Iteration 44, loss = 1.52669683\n",
            "Iteration 45, loss = 1.51058190\n",
            "Iteration 46, loss = 1.51510518\n",
            "Iteration 47, loss = 1.50751856\n",
            "Iteration 48, loss = 1.45888553\n",
            "Iteration 49, loss = 1.50599802\n",
            "Iteration 50, loss = 1.55761095\n",
            "Iteration 51, loss = 1.51116047\n",
            "Iteration 52, loss = 1.48952786\n",
            "Iteration 53, loss = 1.47724714\n",
            "Iteration 54, loss = 1.49407339\n",
            "Iteration 55, loss = 1.49634593\n",
            "Iteration 56, loss = 1.48315195\n",
            "Iteration 57, loss = 1.46138854\n",
            "Iteration 58, loss = 1.45553708\n",
            "Iteration 59, loss = 1.43227072\n",
            "Iteration 60, loss = 1.41372807\n",
            "Iteration 61, loss = 1.43155619\n",
            "Iteration 62, loss = 1.44810925\n",
            "Iteration 63, loss = 1.43338865\n",
            "Iteration 64, loss = 1.44065199\n",
            "Iteration 65, loss = 1.44433495\n",
            "Iteration 66, loss = 1.40500672\n",
            "Iteration 67, loss = 1.41127972\n",
            "Iteration 68, loss = 1.40201657\n",
            "Iteration 69, loss = 1.38667943\n",
            "Iteration 70, loss = 1.39817067\n",
            "Iteration 71, loss = 1.47862460\n",
            "Iteration 72, loss = 1.42157158\n",
            "Iteration 73, loss = 1.38126980\n",
            "Iteration 74, loss = 1.39174858\n",
            "Iteration 75, loss = 1.37750395\n",
            "Iteration 76, loss = 1.49872478\n",
            "Iteration 77, loss = 1.43817460\n",
            "Iteration 78, loss = 1.41575536\n",
            "Iteration 79, loss = 1.40870593\n",
            "Iteration 80, loss = 1.41102177\n",
            "Iteration 81, loss = 1.46009284\n",
            "Iteration 82, loss = 1.43834146\n",
            "Iteration 83, loss = 1.42943795\n",
            "Iteration 84, loss = 1.40583616\n",
            "Iteration 85, loss = 1.40417386\n",
            "Iteration 86, loss = 1.38788861\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000200\n",
            "Iteration 87, loss = 1.40296571\n",
            "Iteration 88, loss = 1.38054122\n",
            "Iteration 89, loss = 1.35473359\n",
            "Iteration 90, loss = 1.35399032\n",
            "Iteration 91, loss = 1.35224517\n",
            "Iteration 92, loss = 1.35405812\n",
            "Iteration 93, loss = 1.34960776\n",
            "Iteration 94, loss = 1.35984903\n",
            "Iteration 95, loss = 1.35688316\n",
            "Iteration 96, loss = 1.34899355\n",
            "Iteration 97, loss = 1.34791209\n",
            "Iteration 98, loss = 1.34740461\n",
            "Iteration 99, loss = 1.34798659\n",
            "Iteration 100, loss = 1.34705171\n",
            "Iteration 101, loss = 1.34839521\n",
            "Iteration 102, loss = 1.35708997\n",
            "Iteration 103, loss = 1.34599419\n",
            "Iteration 104, loss = 1.34716246\n",
            "Iteration 105, loss = 1.34628080\n",
            "Iteration 106, loss = 1.35197259\n",
            "Iteration 107, loss = 1.35126155\n",
            "Iteration 108, loss = 1.34431529\n",
            "Iteration 109, loss = 1.34634253\n",
            "Iteration 110, loss = 1.34897508\n",
            "Iteration 111, loss = 1.34567525\n",
            "Iteration 112, loss = 1.34275107\n",
            "Iteration 113, loss = 1.34247030\n",
            "Iteration 114, loss = 1.34249827\n",
            "Iteration 115, loss = 1.34222679\n",
            "Iteration 116, loss = 1.34213888\n",
            "Iteration 117, loss = 1.34209957\n",
            "Iteration 118, loss = 1.34153886\n",
            "Iteration 119, loss = 1.34120047\n",
            "Iteration 120, loss = 1.34219880\n",
            "Iteration 121, loss = 1.34142363\n",
            "Iteration 122, loss = 1.34162134\n",
            "Iteration 123, loss = 1.34159146\n",
            "Iteration 124, loss = 1.34131910\n",
            "Iteration 125, loss = 1.34086380\n",
            "Iteration 126, loss = 1.34099598\n",
            "Iteration 127, loss = 1.34134529\n",
            "Iteration 128, loss = 1.34150316\n",
            "Iteration 129, loss = 1.34102927\n",
            "Iteration 130, loss = 1.34123813\n",
            "Iteration 131, loss = 1.34092087\n",
            "Iteration 132, loss = 1.34104042\n",
            "Iteration 133, loss = 1.34088036\n",
            "Iteration 134, loss = 1.34103931\n",
            "Iteration 135, loss = 1.34046755\n",
            "Iteration 136, loss = 1.34088715\n",
            "Iteration 137, loss = 1.34040010\n",
            "Iteration 138, loss = 1.34031274\n",
            "Iteration 139, loss = 1.34038165\n",
            "Iteration 140, loss = 1.34070207\n",
            "Iteration 141, loss = 1.34034533\n",
            "Iteration 142, loss = 1.34015957\n",
            "Iteration 143, loss = 1.34010904\n",
            "Iteration 144, loss = 1.34050913\n",
            "Iteration 145, loss = 1.34021955\n",
            "Iteration 146, loss = 1.33961727\n",
            "Iteration 147, loss = 1.34009456\n",
            "Iteration 148, loss = 1.34012842\n",
            "Iteration 149, loss = 1.34005819\n",
            "Iteration 150, loss = 1.33977277\n",
            "Iteration 151, loss = 1.33964205\n",
            "Iteration 152, loss = 1.33984575\n",
            "Iteration 153, loss = 1.33964178\n",
            "Iteration 154, loss = 1.33999768\n",
            "Iteration 155, loss = 1.33961923\n",
            "Iteration 156, loss = 1.33954629\n",
            "Iteration 157, loss = 1.33987514\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000040\n",
            "Iteration 158, loss = 1.33733216\n",
            "Iteration 159, loss = 1.33725492\n",
            "Iteration 160, loss = 1.33726702\n",
            "Iteration 161, loss = 1.33724188\n",
            "Iteration 162, loss = 1.33721283\n",
            "Iteration 163, loss = 1.33714953\n",
            "Iteration 164, loss = 1.33714758\n",
            "Iteration 165, loss = 1.33710989\n",
            "Iteration 166, loss = 1.33714644\n",
            "Iteration 167, loss = 1.33720043\n",
            "Iteration 168, loss = 1.33706800\n",
            "Iteration 169, loss = 1.33709472\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000008\n",
            "Iteration 170, loss = 1.33652526\n",
            "Iteration 171, loss = 1.33653695\n",
            "Iteration 172, loss = 1.33653856\n",
            "Iteration 173, loss = 1.33653174\n",
            "Iteration 174, loss = 1.33652784\n",
            "Iteration 175, loss = 1.33651414\n",
            "Iteration 176, loss = 1.33652383\n",
            "Iteration 177, loss = 1.33653358\n",
            "Iteration 178, loss = 1.33652593\n",
            "Iteration 179, loss = 1.33652144\n",
            "Iteration 180, loss = 1.33652549\n",
            "Iteration 181, loss = 1.33651734\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000002\n",
            "Iteration 182, loss = 1.33640217\n",
            "Iteration 183, loss = 1.33639857\n",
            "Iteration 184, loss = 1.33639811\n",
            "Iteration 185, loss = 1.33639805\n",
            "Iteration 186, loss = 1.33639765\n",
            "Iteration 187, loss = 1.33639881\n",
            "Iteration 188, loss = 1.33639724\n",
            "Iteration 189, loss = 1.33639676\n",
            "Iteration 190, loss = 1.33639798\n",
            "Iteration 191, loss = 1.33639645\n",
            "Iteration 192, loss = 1.33639870\n",
            "Iteration 193, loss = 1.33639503\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000000\n",
            "Iteration 194, loss = 1.33637201\n",
            "Iteration 195, loss = 1.33637195\n",
            "Iteration 196, loss = 1.33637160\n",
            "Iteration 197, loss = 1.33637150\n",
            "Iteration 198, loss = 1.33637143\n",
            "Iteration 199, loss = 1.33637161\n",
            "Iteration 200, loss = 1.33637124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.13232498\n",
            "Iteration 2, loss = 2.00199504\n",
            "Iteration 3, loss = 1.92862222\n",
            "Iteration 4, loss = 1.95052859\n",
            "Iteration 5, loss = 1.91238479\n",
            "Iteration 6, loss = 1.92363158\n",
            "Iteration 7, loss = 1.91436732\n",
            "Iteration 8, loss = 1.90608002\n",
            "Iteration 9, loss = 1.89152137\n",
            "Iteration 10, loss = 1.92693653\n",
            "Iteration 11, loss = 1.86799446\n",
            "Iteration 12, loss = 1.76979363\n",
            "Iteration 13, loss = 1.75926967\n",
            "Iteration 14, loss = 1.73911967\n",
            "Iteration 15, loss = 1.60621310\n",
            "Iteration 16, loss = 1.50871737\n",
            "Iteration 17, loss = 1.39587837\n",
            "Iteration 18, loss = 1.23566398\n",
            "Iteration 19, loss = 1.09755459\n",
            "Iteration 20, loss = 1.05589185\n",
            "Iteration 21, loss = 1.04245351\n",
            "Iteration 22, loss = 1.08899445\n",
            "Iteration 23, loss = 1.07094315\n",
            "Iteration 24, loss = 1.15415302\n",
            "Iteration 25, loss = 1.01783990\n",
            "Iteration 26, loss = 0.99860725\n",
            "Iteration 27, loss = 1.00700184\n",
            "Iteration 28, loss = 1.00452656\n",
            "Iteration 29, loss = 1.05524250\n",
            "Iteration 30, loss = 0.95375586\n",
            "Iteration 31, loss = 1.16208644\n",
            "Iteration 32, loss = 1.00250773\n",
            "Iteration 33, loss = 1.01796093\n",
            "Iteration 34, loss = 1.00061853\n",
            "Iteration 35, loss = 1.07004767\n",
            "Iteration 36, loss = 0.96311597\n",
            "Iteration 37, loss = 0.99949755\n",
            "Iteration 38, loss = 0.98715246\n",
            "Iteration 39, loss = 0.97612898\n",
            "Iteration 40, loss = 0.99643667\n",
            "Iteration 41, loss = 0.98575441\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000200\n",
            "Iteration 42, loss = 0.91320021\n",
            "Iteration 43, loss = 0.89892804\n",
            "Iteration 44, loss = 0.89090203\n",
            "Iteration 45, loss = 0.88593079\n",
            "Iteration 46, loss = 0.88472697\n",
            "Iteration 47, loss = 0.86197251\n",
            "Iteration 48, loss = 0.86515140\n",
            "Iteration 49, loss = 0.84186255\n",
            "Iteration 50, loss = 0.83768420\n",
            "Iteration 51, loss = 0.81507265\n",
            "Iteration 52, loss = 0.80585583\n",
            "Iteration 53, loss = 0.79463008\n",
            "Iteration 54, loss = 0.80135910\n",
            "Iteration 55, loss = 0.79856967\n",
            "Iteration 56, loss = 0.78863248\n",
            "Iteration 57, loss = 0.79154009\n",
            "Iteration 58, loss = 0.80012249\n",
            "Iteration 59, loss = 0.78880266\n",
            "Iteration 60, loss = 0.78605815\n",
            "Iteration 61, loss = 0.78074781\n",
            "Iteration 62, loss = 0.78071693\n",
            "Iteration 63, loss = 0.76198221\n",
            "Iteration 64, loss = 0.77193921\n",
            "Iteration 65, loss = 0.76436800\n",
            "Iteration 66, loss = 0.77597096\n",
            "Iteration 67, loss = 0.76747678\n",
            "Iteration 68, loss = 0.76854596\n",
            "Iteration 69, loss = 0.76498089\n",
            "Iteration 70, loss = 0.76733535\n",
            "Iteration 71, loss = 0.74748902\n",
            "Iteration 72, loss = 0.75175371\n",
            "Iteration 73, loss = 0.76329179\n",
            "Iteration 74, loss = 0.77094999\n",
            "Iteration 75, loss = 0.75598708\n",
            "Iteration 76, loss = 0.73581347\n",
            "Iteration 77, loss = 0.73271106\n",
            "Iteration 78, loss = 0.73753115\n",
            "Iteration 79, loss = 0.74977086\n",
            "Iteration 80, loss = 0.75449543\n",
            "Iteration 81, loss = 0.70767534\n",
            "Iteration 82, loss = 0.71988772\n",
            "Iteration 83, loss = 0.70429231\n",
            "Iteration 84, loss = 0.72576497\n",
            "Iteration 85, loss = 0.72261668\n",
            "Iteration 86, loss = 0.71678476\n",
            "Iteration 87, loss = 0.73595281\n",
            "Iteration 88, loss = 0.74114656\n",
            "Iteration 89, loss = 0.71513976\n",
            "Iteration 90, loss = 0.72421229\n",
            "Iteration 91, loss = 0.71196106\n",
            "Iteration 92, loss = 0.70647771\n",
            "Iteration 93, loss = 0.69756489\n",
            "Iteration 94, loss = 0.69010735\n",
            "Iteration 95, loss = 0.72953930\n",
            "Iteration 96, loss = 0.70766699\n",
            "Iteration 97, loss = 0.72173454\n",
            "Iteration 98, loss = 0.71073214\n",
            "Iteration 99, loss = 0.71347810\n",
            "Iteration 100, loss = 0.70970545\n",
            "Iteration 101, loss = 0.71461157\n",
            "Iteration 102, loss = 0.70583627\n",
            "Iteration 103, loss = 0.68631090\n",
            "Iteration 104, loss = 0.69450873\n",
            "Iteration 105, loss = 0.70936896\n",
            "Iteration 106, loss = 0.68451401\n",
            "Iteration 107, loss = 0.69846364\n",
            "Iteration 108, loss = 0.69512910\n",
            "Iteration 109, loss = 0.70914828\n",
            "Iteration 110, loss = 0.70150142\n",
            "Iteration 111, loss = 0.68220933\n",
            "Iteration 112, loss = 0.67556396\n",
            "Iteration 113, loss = 0.70090973\n",
            "Iteration 114, loss = 0.67223217\n",
            "Iteration 115, loss = 0.67747637\n",
            "Iteration 116, loss = 0.66408710\n",
            "Iteration 117, loss = 0.67502741\n",
            "Iteration 118, loss = 0.68914405\n",
            "Iteration 119, loss = 0.67805529\n",
            "Iteration 120, loss = 0.68199998\n",
            "Iteration 121, loss = 0.67360279\n",
            "Iteration 122, loss = 0.66767187\n",
            "Iteration 123, loss = 0.69677552\n",
            "Iteration 124, loss = 0.69991503\n",
            "Iteration 125, loss = 0.70584039\n",
            "Iteration 126, loss = 0.66920585\n",
            "Iteration 127, loss = 0.67318446\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000040\n",
            "Iteration 128, loss = 0.68809254\n",
            "Iteration 129, loss = 0.66380353\n",
            "Iteration 130, loss = 0.65344827\n",
            "Iteration 131, loss = 0.63948602\n",
            "Iteration 132, loss = 0.63772209\n",
            "Iteration 133, loss = 0.63718782\n",
            "Iteration 134, loss = 0.63780245\n",
            "Iteration 135, loss = 0.63848078\n",
            "Iteration 136, loss = 0.63648451\n",
            "Iteration 137, loss = 0.64029118\n",
            "Iteration 138, loss = 0.64366102\n",
            "Iteration 139, loss = 0.63674521\n",
            "Iteration 140, loss = 0.63303632\n",
            "Iteration 141, loss = 0.62998828\n",
            "Iteration 142, loss = 0.62994314\n",
            "Iteration 143, loss = 0.63369405\n",
            "Iteration 144, loss = 0.63055337\n",
            "Iteration 145, loss = 0.63287316\n",
            "Iteration 146, loss = 0.62918544\n",
            "Iteration 147, loss = 0.62688460\n",
            "Iteration 148, loss = 0.62676917\n",
            "Iteration 149, loss = 0.62679558\n",
            "Iteration 150, loss = 0.62660457\n",
            "Iteration 151, loss = 0.62651124\n",
            "Iteration 152, loss = 0.62641269\n",
            "Iteration 153, loss = 0.62650432\n",
            "Iteration 154, loss = 0.62624400\n",
            "Iteration 155, loss = 0.62624713\n",
            "Iteration 156, loss = 0.62611113\n",
            "Iteration 157, loss = 0.62603976\n",
            "Iteration 158, loss = 0.62597423\n",
            "Iteration 159, loss = 0.62585343\n",
            "Iteration 160, loss = 0.62577720\n",
            "Iteration 161, loss = 0.62583041\n",
            "Iteration 162, loss = 0.62573938\n",
            "Iteration 163, loss = 0.62559648\n",
            "Iteration 164, loss = 0.62574153\n",
            "Iteration 165, loss = 0.62580267\n",
            "Iteration 166, loss = 0.62544277\n",
            "Iteration 167, loss = 0.62532583\n",
            "Iteration 168, loss = 0.62531638\n",
            "Iteration 169, loss = 0.62535508\n",
            "Iteration 170, loss = 0.62541894\n",
            "Iteration 171, loss = 0.62524429\n",
            "Iteration 172, loss = 0.62524438\n",
            "Iteration 173, loss = 0.62583174\n",
            "Iteration 174, loss = 0.62581648\n",
            "Iteration 175, loss = 0.62551096\n",
            "Iteration 176, loss = 0.62377924\n",
            "Iteration 177, loss = 0.62298541\n",
            "Iteration 178, loss = 0.62247067\n",
            "Iteration 179, loss = 0.62241365\n",
            "Iteration 180, loss = 0.62235883\n",
            "Iteration 181, loss = 0.62228685\n",
            "Iteration 182, loss = 0.62216246\n",
            "Iteration 183, loss = 0.62207677\n",
            "Iteration 184, loss = 0.62208411\n",
            "Iteration 185, loss = 0.62202354\n",
            "Iteration 186, loss = 0.62198069\n",
            "Iteration 187, loss = 0.62185707\n",
            "Iteration 188, loss = 0.62186270\n",
            "Iteration 189, loss = 0.62178373\n",
            "Iteration 190, loss = 0.62171889\n",
            "Iteration 191, loss = 0.62165167\n",
            "Iteration 192, loss = 0.62157073\n",
            "Iteration 193, loss = 0.62159556\n",
            "Iteration 194, loss = 0.62153282\n",
            "Iteration 195, loss = 0.62149908\n",
            "Iteration 196, loss = 0.62144798\n",
            "Iteration 197, loss = 0.62144291\n",
            "Iteration 198, loss = 0.62139731\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000008\n",
            "Iteration 199, loss = 0.62104328\n",
            "Iteration 200, loss = 0.62102853\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.25503991\n",
            "Iteration 2, loss = 1.87557607\n",
            "Iteration 3, loss = 1.55064568\n",
            "Iteration 4, loss = 1.36414158\n",
            "Iteration 5, loss = 1.35001229\n",
            "Iteration 6, loss = 1.28739164\n",
            "Iteration 7, loss = 1.15896060\n",
            "Iteration 8, loss = 1.09651638\n",
            "Iteration 9, loss = 1.16006828\n",
            "Iteration 10, loss = 1.09030337\n",
            "Iteration 11, loss = 1.07166700\n",
            "Iteration 12, loss = 1.09600615\n",
            "Iteration 13, loss = 1.00334993\n",
            "Iteration 14, loss = 0.98006207\n",
            "Iteration 15, loss = 0.96311969\n",
            "Iteration 16, loss = 1.17497694\n",
            "Iteration 17, loss = 1.14510080\n",
            "Iteration 18, loss = 1.03119855\n",
            "Iteration 19, loss = 0.94185474\n",
            "Iteration 20, loss = 0.94816579\n",
            "Iteration 21, loss = 1.04329245\n",
            "Iteration 22, loss = 0.91930462\n",
            "Iteration 23, loss = 0.93457640\n",
            "Iteration 24, loss = 0.86816261\n",
            "Iteration 25, loss = 0.83572311\n",
            "Iteration 26, loss = 0.89437032\n",
            "Iteration 27, loss = 1.01870063\n",
            "Iteration 28, loss = 0.96242904\n",
            "Iteration 29, loss = 0.86900914\n",
            "Iteration 30, loss = 0.89481073\n",
            "Iteration 31, loss = 0.88653605\n",
            "Iteration 32, loss = 0.97688624\n",
            "Iteration 33, loss = 1.01015607\n",
            "Iteration 34, loss = 0.99479599\n",
            "Iteration 35, loss = 0.89646629\n",
            "Iteration 36, loss = 0.88515624\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000200\n",
            "Iteration 37, loss = 0.78484580\n",
            "Iteration 38, loss = 0.78550189\n",
            "Iteration 39, loss = 0.74586509\n",
            "Iteration 40, loss = 0.74939719\n",
            "Iteration 41, loss = 0.74704639\n",
            "Iteration 42, loss = 0.74090153\n",
            "Iteration 43, loss = 0.76694378\n",
            "Iteration 44, loss = 0.73037440\n",
            "Iteration 45, loss = 0.71645789\n",
            "Iteration 46, loss = 0.71597144\n",
            "Iteration 47, loss = 0.70645872\n",
            "Iteration 48, loss = 0.70173953\n",
            "Iteration 49, loss = 0.69720422\n",
            "Iteration 50, loss = 0.69340257\n",
            "Iteration 51, loss = 0.68871211\n",
            "Iteration 52, loss = 0.69271490\n",
            "Iteration 53, loss = 0.69420425\n",
            "Iteration 54, loss = 0.69881814\n",
            "Iteration 55, loss = 0.69717468\n",
            "Iteration 56, loss = 0.72801629\n",
            "Iteration 57, loss = 0.72708097\n",
            "Iteration 58, loss = 0.70773956\n",
            "Iteration 59, loss = 0.71266859\n",
            "Iteration 60, loss = 0.70323369\n",
            "Iteration 61, loss = 0.68943706\n",
            "Iteration 62, loss = 0.68653094\n",
            "Iteration 63, loss = 0.68453723\n",
            "Iteration 64, loss = 0.68624723\n",
            "Iteration 65, loss = 0.67793008\n",
            "Iteration 66, loss = 0.67730539\n",
            "Iteration 67, loss = 0.67710452\n",
            "Iteration 68, loss = 0.67662320\n",
            "Iteration 69, loss = 0.67783703\n",
            "Iteration 70, loss = 0.67869237\n",
            "Iteration 71, loss = 0.67833332\n",
            "Iteration 72, loss = 0.68763856\n",
            "Iteration 73, loss = 0.67944256\n",
            "Iteration 74, loss = 0.68159286\n",
            "Iteration 75, loss = 0.66348361\n",
            "Iteration 76, loss = 0.67766791\n",
            "Iteration 77, loss = 0.68437276\n",
            "Iteration 78, loss = 0.67637954\n",
            "Iteration 79, loss = 0.67367298\n",
            "Iteration 80, loss = 0.67689157\n",
            "Iteration 81, loss = 0.67629470\n",
            "Iteration 82, loss = 0.67420496\n",
            "Iteration 83, loss = 0.68634368\n",
            "Iteration 84, loss = 0.68089428\n",
            "Iteration 85, loss = 0.68348619\n",
            "Iteration 86, loss = 0.67759141\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000040\n",
            "Iteration 87, loss = 0.66532067\n",
            "Iteration 88, loss = 0.66352804\n",
            "Iteration 89, loss = 0.66339600\n",
            "Iteration 90, loss = 0.66331373\n",
            "Iteration 91, loss = 0.66319858\n",
            "Iteration 92, loss = 0.66311684\n",
            "Iteration 93, loss = 0.66307115\n",
            "Iteration 94, loss = 0.66299613\n",
            "Iteration 95, loss = 0.66297085\n",
            "Iteration 96, loss = 0.66288609\n",
            "Iteration 97, loss = 0.66286082\n",
            "Iteration 98, loss = 0.66278784\n",
            "Iteration 99, loss = 0.66275395\n",
            "Iteration 100, loss = 0.66267341\n",
            "Iteration 101, loss = 0.66262978\n",
            "Iteration 102, loss = 0.66257345\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000008\n",
            "Iteration 103, loss = 0.66218613\n",
            "Iteration 104, loss = 0.66216618\n",
            "Iteration 105, loss = 0.66214983\n",
            "Iteration 106, loss = 0.66212106\n",
            "Iteration 107, loss = 0.66209752\n",
            "Iteration 108, loss = 0.66205931\n",
            "Iteration 109, loss = 0.66201511\n",
            "Iteration 110, loss = 0.66196990\n",
            "Iteration 111, loss = 0.66190167\n",
            "Iteration 112, loss = 0.66180531\n",
            "Iteration 113, loss = 0.66171685\n",
            "Iteration 114, loss = 0.66146430\n",
            "Iteration 115, loss = 0.66117484\n",
            "Iteration 116, loss = 0.66076328\n",
            "Iteration 117, loss = 0.66047400\n",
            "Iteration 118, loss = 0.66032219\n",
            "Iteration 119, loss = 0.66021256\n",
            "Iteration 120, loss = 0.66012494\n",
            "Iteration 121, loss = 0.66008398\n",
            "Iteration 122, loss = 0.66004002\n",
            "Iteration 123, loss = 0.66000676\n",
            "Iteration 124, loss = 0.65997336\n",
            "Iteration 125, loss = 0.65995474\n",
            "Iteration 126, loss = 0.65992577\n",
            "Iteration 127, loss = 0.65990703\n",
            "Iteration 128, loss = 0.65988935\n",
            "Iteration 129, loss = 0.65987399\n",
            "Iteration 130, loss = 0.65985363\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000002\n",
            "Iteration 131, loss = 0.65977346\n",
            "Iteration 132, loss = 0.65977137\n",
            "Iteration 133, loss = 0.65976797\n",
            "Iteration 134, loss = 0.65976607\n",
            "Iteration 135, loss = 0.65976124\n",
            "Iteration 136, loss = 0.65975911\n",
            "Iteration 137, loss = 0.65975595\n",
            "Iteration 138, loss = 0.65975285\n",
            "Iteration 139, loss = 0.65975104\n",
            "Iteration 140, loss = 0.65974666\n",
            "Iteration 141, loss = 0.65974513\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000000\n",
            "Iteration 142, loss = 0.65972802\n",
            "Iteration 143, loss = 0.65972746\n",
            "Iteration 144, loss = 0.65972683\n",
            "Iteration 145, loss = 0.65972631\n",
            "Iteration 146, loss = 0.65972564\n",
            "Iteration 147, loss = 0.65972495\n",
            "Iteration 148, loss = 0.65972440\n",
            "Iteration 149, loss = 0.65972415\n",
            "Iteration 150, loss = 0.65972359\n",
            "Iteration 151, loss = 0.65972294\n",
            "Iteration 152, loss = 0.65972225\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Learning rate too small. Stopping.\n",
            "Hidden layer structure: 5\n",
            "Best loss: 0.8723740073536798\n",
            "Training accuracy: 62.21161495624502\n",
            "Test accuracy: 57.407407407407405\n",
            "Iteration 1, loss = 1.86232373\n",
            "Iteration 2, loss = 1.42979357\n",
            "Iteration 3, loss = 1.21343741\n",
            "Iteration 4, loss = 1.09565739\n",
            "Iteration 5, loss = 1.06016915\n",
            "Iteration 6, loss = 0.90847497\n",
            "Iteration 7, loss = 0.77815110\n",
            "Iteration 8, loss = 0.81025339\n",
            "Iteration 9, loss = 0.93498094\n",
            "Iteration 10, loss = 0.75287201\n",
            "Iteration 11, loss = 0.73708524\n",
            "Iteration 12, loss = 0.63501013\n",
            "Iteration 13, loss = 0.66631661\n",
            "Iteration 14, loss = 0.69690907\n",
            "Iteration 15, loss = 0.67688675\n",
            "Iteration 16, loss = 0.61839393\n",
            "Iteration 17, loss = 0.63092541\n",
            "Iteration 18, loss = 0.63363310\n",
            "Iteration 19, loss = 0.53702439\n",
            "Iteration 20, loss = 0.51325379\n",
            "Iteration 21, loss = 0.51412515\n",
            "Iteration 22, loss = 0.55867905\n",
            "Iteration 23, loss = 0.78848998\n",
            "Iteration 24, loss = 0.55779116\n",
            "Iteration 25, loss = 0.51681119\n",
            "Iteration 26, loss = 0.45970429\n",
            "Iteration 27, loss = 0.43516888\n",
            "Iteration 28, loss = 0.49527639\n",
            "Iteration 29, loss = 0.49650444\n",
            "Iteration 30, loss = 0.46153900\n",
            "Iteration 31, loss = 0.50470074\n",
            "Iteration 32, loss = 0.50905749\n",
            "Iteration 33, loss = 0.50700763\n",
            "Iteration 34, loss = 0.53653571\n",
            "Iteration 35, loss = 0.46981183\n",
            "Iteration 36, loss = 0.40065248\n",
            "Iteration 37, loss = 0.45584249\n",
            "Iteration 38, loss = 0.51711572\n",
            "Iteration 39, loss = 0.45336089\n",
            "Iteration 40, loss = 0.44660113\n",
            "Iteration 41, loss = 0.44424083\n",
            "Iteration 42, loss = 0.53336571\n",
            "Iteration 43, loss = 0.48020821\n",
            "Iteration 44, loss = 0.39000432\n",
            "Iteration 45, loss = 0.58805604\n",
            "Iteration 46, loss = 0.43463637\n",
            "Iteration 47, loss = 0.40479871\n",
            "Iteration 48, loss = 0.47465971\n",
            "Iteration 49, loss = 0.77860128\n",
            "Iteration 50, loss = 0.75057085\n",
            "Iteration 51, loss = 0.51005596\n",
            "Iteration 52, loss = 0.56050681\n",
            "Iteration 53, loss = 0.50449413\n",
            "Iteration 54, loss = 0.68538445\n",
            "Iteration 55, loss = 0.46070911\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000200\n",
            "Iteration 56, loss = 0.32012919\n",
            "Iteration 57, loss = 0.29844478\n",
            "Iteration 58, loss = 0.29728171\n",
            "Iteration 59, loss = 0.27803769\n",
            "Iteration 60, loss = 0.27940688\n",
            "Iteration 61, loss = 0.27078222\n",
            "Iteration 62, loss = 0.27471455\n",
            "Iteration 63, loss = 0.27608402\n",
            "Iteration 64, loss = 0.26939618\n",
            "Iteration 65, loss = 0.26432695\n",
            "Iteration 66, loss = 0.26718341\n",
            "Iteration 67, loss = 0.26443742\n",
            "Iteration 68, loss = 0.26144103\n",
            "Iteration 69, loss = 0.26397120\n",
            "Iteration 70, loss = 0.26794652\n",
            "Iteration 71, loss = 0.25466286\n",
            "Iteration 72, loss = 0.25126615\n",
            "Iteration 73, loss = 0.25606878\n",
            "Iteration 74, loss = 0.25022420\n",
            "Iteration 75, loss = 0.25862614\n",
            "Iteration 76, loss = 0.24758844\n",
            "Iteration 77, loss = 0.24305553\n",
            "Iteration 78, loss = 0.24045464\n",
            "Iteration 79, loss = 0.24113685\n",
            "Iteration 80, loss = 0.23791675\n",
            "Iteration 81, loss = 0.24254548\n",
            "Iteration 82, loss = 0.23408655\n",
            "Iteration 83, loss = 0.23372802\n",
            "Iteration 84, loss = 0.22926018\n",
            "Iteration 85, loss = 0.23509528\n",
            "Iteration 86, loss = 0.23472973\n",
            "Iteration 87, loss = 0.23151964\n",
            "Iteration 88, loss = 0.23056444\n",
            "Iteration 89, loss = 0.22553027\n",
            "Iteration 90, loss = 0.22524163\n",
            "Iteration 91, loss = 0.22510401\n",
            "Iteration 92, loss = 0.22705447\n",
            "Iteration 93, loss = 0.22687671\n",
            "Iteration 94, loss = 0.22977706\n",
            "Iteration 95, loss = 0.22685206\n",
            "Iteration 96, loss = 0.22922664\n",
            "Iteration 97, loss = 0.22015882\n",
            "Iteration 98, loss = 0.21945556\n",
            "Iteration 99, loss = 0.21816138\n",
            "Iteration 100, loss = 0.21935428\n",
            "Iteration 101, loss = 0.21801351\n",
            "Iteration 102, loss = 0.21746259\n",
            "Iteration 103, loss = 0.21986958\n",
            "Iteration 104, loss = 0.21627349\n",
            "Iteration 105, loss = 0.22592804\n",
            "Iteration 106, loss = 0.22062368\n",
            "Iteration 107, loss = 0.21983224\n",
            "Iteration 108, loss = 0.21760463\n",
            "Iteration 109, loss = 0.21902350\n",
            "Iteration 110, loss = 0.21409841\n",
            "Iteration 111, loss = 0.21484754\n",
            "Iteration 112, loss = 0.21269394\n",
            "Iteration 113, loss = 0.21296043\n",
            "Iteration 114, loss = 0.21344621\n",
            "Iteration 115, loss = 0.21313541\n",
            "Iteration 116, loss = 0.21282368\n",
            "Iteration 117, loss = 0.21103886\n",
            "Iteration 118, loss = 0.20914455\n",
            "Iteration 119, loss = 0.20745732\n",
            "Iteration 120, loss = 0.20746562\n",
            "Iteration 121, loss = 0.20718139\n",
            "Iteration 122, loss = 0.20954484\n",
            "Iteration 123, loss = 0.20646329\n",
            "Iteration 124, loss = 0.20621532\n",
            "Iteration 125, loss = 0.20580918\n",
            "Iteration 126, loss = 0.20567394\n",
            "Iteration 127, loss = 0.20589577\n",
            "Iteration 128, loss = 0.20530443\n",
            "Iteration 129, loss = 0.20543267\n",
            "Iteration 130, loss = 0.20534874\n",
            "Iteration 131, loss = 0.20544231\n",
            "Iteration 132, loss = 0.20418754\n",
            "Iteration 133, loss = 0.20427040\n",
            "Iteration 134, loss = 0.20755381\n",
            "Iteration 135, loss = 0.20379813\n",
            "Iteration 136, loss = 0.20428620\n",
            "Iteration 137, loss = 0.20367296\n",
            "Iteration 138, loss = 0.20330037\n",
            "Iteration 139, loss = 0.20312866\n",
            "Iteration 140, loss = 0.20319535\n",
            "Iteration 141, loss = 0.20249213\n",
            "Iteration 142, loss = 0.20144386\n",
            "Iteration 143, loss = 0.20143005\n",
            "Iteration 144, loss = 0.20157378\n",
            "Iteration 145, loss = 0.20059283\n",
            "Iteration 146, loss = 0.20299104\n",
            "Iteration 147, loss = 0.20065433\n",
            "Iteration 148, loss = 0.19967147\n",
            "Iteration 149, loss = 0.20141492\n",
            "Iteration 150, loss = 0.19932487\n",
            "Iteration 151, loss = 0.19915820\n",
            "Iteration 152, loss = 0.19947977\n",
            "Iteration 153, loss = 0.19974965\n",
            "Iteration 154, loss = 0.19713096\n",
            "Iteration 155, loss = 0.19721594\n",
            "Iteration 156, loss = 0.19681406\n",
            "Iteration 157, loss = 0.19632569\n",
            "Iteration 158, loss = 0.19665752\n",
            "Iteration 159, loss = 0.19565985\n",
            "Iteration 160, loss = 0.19679181\n",
            "Iteration 161, loss = 0.19694115\n",
            "Iteration 162, loss = 0.19573229\n",
            "Iteration 163, loss = 0.19561745\n",
            "Iteration 164, loss = 0.19642639\n",
            "Iteration 165, loss = 0.19580097\n",
            "Iteration 166, loss = 0.19522300\n",
            "Iteration 167, loss = 0.19496596\n",
            "Iteration 168, loss = 0.19463506\n",
            "Iteration 169, loss = 0.19590060\n",
            "Iteration 170, loss = 0.19497358\n",
            "Iteration 171, loss = 0.19608581\n",
            "Iteration 172, loss = 0.19513896\n",
            "Iteration 173, loss = 0.19504357\n",
            "Iteration 174, loss = 0.19477335\n",
            "Iteration 175, loss = 0.19452470\n",
            "Iteration 176, loss = 0.19394928\n",
            "Iteration 177, loss = 0.19355089\n",
            "Iteration 178, loss = 0.19367821\n",
            "Iteration 179, loss = 0.19400920\n",
            "Iteration 180, loss = 0.19395296\n",
            "Iteration 181, loss = 0.19334830\n",
            "Iteration 182, loss = 0.19336266\n",
            "Iteration 183, loss = 0.19277085\n",
            "Iteration 184, loss = 0.19319049\n",
            "Iteration 185, loss = 0.19299649\n",
            "Iteration 186, loss = 0.19279969\n",
            "Iteration 187, loss = 0.19209498\n",
            "Iteration 188, loss = 0.19261758\n",
            "Iteration 189, loss = 0.19242475\n",
            "Iteration 190, loss = 0.19225031\n",
            "Iteration 191, loss = 0.19196138\n",
            "Iteration 192, loss = 0.19249669\n",
            "Iteration 193, loss = 0.19693060\n",
            "Iteration 194, loss = 0.19672614\n",
            "Iteration 195, loss = 0.19282966\n",
            "Iteration 196, loss = 0.19265481\n",
            "Iteration 197, loss = 0.19248771\n",
            "Iteration 198, loss = 0.20599103\n",
            "Iteration 199, loss = 0.19223039\n",
            "Iteration 200, loss = 0.21255638\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.07029331\n",
            "Iteration 2, loss = 1.78711641\n",
            "Iteration 3, loss = 1.41684929\n",
            "Iteration 4, loss = 1.27434504\n",
            "Iteration 5, loss = 1.18240082\n",
            "Iteration 6, loss = 1.02931908\n",
            "Iteration 7, loss = 1.01288893\n",
            "Iteration 8, loss = 0.98538592\n",
            "Iteration 9, loss = 0.82802038\n",
            "Iteration 10, loss = 0.69747465\n",
            "Iteration 11, loss = 0.57315538\n",
            "Iteration 12, loss = 0.61695003\n",
            "Iteration 13, loss = 0.55883026\n",
            "Iteration 14, loss = 0.67843001\n",
            "Iteration 15, loss = 0.53862858\n",
            "Iteration 16, loss = 0.51350570\n",
            "Iteration 17, loss = 0.53544204\n",
            "Iteration 18, loss = 0.45980982\n",
            "Iteration 19, loss = 0.45960895\n",
            "Iteration 20, loss = 0.47395755\n",
            "Iteration 21, loss = 0.41923735\n",
            "Iteration 22, loss = 0.41963671\n",
            "Iteration 23, loss = 0.32195296\n",
            "Iteration 24, loss = 0.40294778\n",
            "Iteration 25, loss = 0.42284935\n",
            "Iteration 26, loss = 0.41415895\n",
            "Iteration 27, loss = 0.37435415\n",
            "Iteration 28, loss = 0.38855078\n",
            "Iteration 29, loss = 0.62788894\n",
            "Iteration 30, loss = 0.43358443\n",
            "Iteration 31, loss = 0.46822796\n",
            "Iteration 32, loss = 0.38050504\n",
            "Iteration 33, loss = 0.33005053\n",
            "Iteration 34, loss = 0.34242288\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000200\n",
            "Iteration 35, loss = 0.30941526\n",
            "Iteration 36, loss = 0.26959308\n",
            "Iteration 37, loss = 0.25522966\n",
            "Iteration 38, loss = 0.24451359\n",
            "Iteration 39, loss = 0.22607655\n",
            "Iteration 40, loss = 0.25296777\n",
            "Iteration 41, loss = 0.22643365\n",
            "Iteration 42, loss = 0.22059551\n",
            "Iteration 43, loss = 0.21743742\n",
            "Iteration 44, loss = 0.21239570\n",
            "Iteration 45, loss = 0.20628188\n",
            "Iteration 46, loss = 0.20893426\n",
            "Iteration 47, loss = 0.20775139\n",
            "Iteration 48, loss = 0.19257858\n",
            "Iteration 49, loss = 0.19075456\n",
            "Iteration 50, loss = 0.19267205\n",
            "Iteration 51, loss = 0.18465901\n",
            "Iteration 52, loss = 0.17614101\n",
            "Iteration 53, loss = 0.17457243\n",
            "Iteration 54, loss = 0.18784641\n",
            "Iteration 55, loss = 0.18213201\n",
            "Iteration 56, loss = 0.17161548\n",
            "Iteration 57, loss = 0.17073543\n",
            "Iteration 58, loss = 0.17595455\n",
            "Iteration 59, loss = 0.17827868\n",
            "Iteration 60, loss = 0.16873248\n",
            "Iteration 61, loss = 0.17518547\n",
            "Iteration 62, loss = 0.17072002\n",
            "Iteration 63, loss = 0.18420894\n",
            "Iteration 64, loss = 0.17504883\n",
            "Iteration 65, loss = 0.16653125\n",
            "Iteration 66, loss = 0.16165582\n",
            "Iteration 67, loss = 0.15856799\n",
            "Iteration 68, loss = 0.16220318\n",
            "Iteration 69, loss = 0.16128900\n",
            "Iteration 70, loss = 0.15636908\n",
            "Iteration 71, loss = 0.16712165\n",
            "Iteration 72, loss = 0.15316340\n",
            "Iteration 73, loss = 0.15054052\n",
            "Iteration 74, loss = 0.14984270\n",
            "Iteration 75, loss = 0.15139713\n",
            "Iteration 76, loss = 0.14824136\n",
            "Iteration 77, loss = 0.14769633\n",
            "Iteration 78, loss = 0.14581279\n",
            "Iteration 79, loss = 0.14997785\n",
            "Iteration 80, loss = 0.14355708\n",
            "Iteration 81, loss = 0.14529957\n",
            "Iteration 82, loss = 0.15438323\n",
            "Iteration 83, loss = 0.14572500\n",
            "Iteration 84, loss = 0.14921006\n",
            "Iteration 85, loss = 0.14470220\n",
            "Iteration 86, loss = 0.14565031\n",
            "Iteration 87, loss = 0.15094806\n",
            "Iteration 88, loss = 0.14570510\n",
            "Iteration 89, loss = 0.14611780\n",
            "Iteration 90, loss = 0.13985209\n",
            "Iteration 91, loss = 0.13958370\n",
            "Iteration 92, loss = 0.14097283\n",
            "Iteration 93, loss = 0.14269810\n",
            "Iteration 94, loss = 0.13510718\n",
            "Iteration 95, loss = 0.14458058\n",
            "Iteration 96, loss = 0.13086669\n",
            "Iteration 97, loss = 0.12958460\n",
            "Iteration 98, loss = 0.12907434\n",
            "Iteration 99, loss = 0.13306950\n",
            "Iteration 100, loss = 0.13303078\n",
            "Iteration 101, loss = 0.12809978\n",
            "Iteration 102, loss = 0.12871760\n",
            "Iteration 103, loss = 0.12669118\n",
            "Iteration 104, loss = 0.12457732\n",
            "Iteration 105, loss = 0.12965369\n",
            "Iteration 106, loss = 0.13125687\n",
            "Iteration 107, loss = 0.12615995\n",
            "Iteration 108, loss = 0.13073012\n",
            "Iteration 109, loss = 0.12497424\n",
            "Iteration 110, loss = 0.12737835\n",
            "Iteration 111, loss = 0.13032696\n",
            "Iteration 112, loss = 0.12915276\n",
            "Iteration 113, loss = 0.12413490\n",
            "Iteration 114, loss = 0.12313670\n",
            "Iteration 115, loss = 0.12226871\n",
            "Iteration 116, loss = 0.12129869\n",
            "Iteration 117, loss = 0.12326812\n",
            "Iteration 118, loss = 0.12094162\n",
            "Iteration 119, loss = 0.12004896\n",
            "Iteration 120, loss = 0.11980829\n",
            "Iteration 121, loss = 0.12404555\n",
            "Iteration 122, loss = 0.11913649\n",
            "Iteration 123, loss = 0.12120148\n",
            "Iteration 124, loss = 0.11858657\n",
            "Iteration 125, loss = 0.11813793\n",
            "Iteration 126, loss = 0.11715989\n",
            "Iteration 127, loss = 0.11780584\n",
            "Iteration 128, loss = 0.11757222\n",
            "Iteration 129, loss = 0.11739313\n",
            "Iteration 130, loss = 0.11688969\n",
            "Iteration 131, loss = 0.11664901\n",
            "Iteration 132, loss = 0.11632015\n",
            "Iteration 133, loss = 0.11587059\n",
            "Iteration 134, loss = 0.11595757\n",
            "Iteration 135, loss = 0.11516866\n",
            "Iteration 136, loss = 0.11482005\n",
            "Iteration 137, loss = 0.11459061\n",
            "Iteration 138, loss = 0.11456811\n",
            "Iteration 139, loss = 0.11434887\n",
            "Iteration 140, loss = 0.11447491\n",
            "Iteration 141, loss = 0.11385563\n",
            "Iteration 142, loss = 0.11323688\n",
            "Iteration 143, loss = 0.11339106\n",
            "Iteration 144, loss = 0.11306707\n",
            "Iteration 145, loss = 0.11291401\n",
            "Iteration 146, loss = 0.11272305\n",
            "Iteration 147, loss = 0.11258721\n",
            "Iteration 148, loss = 0.11244347\n",
            "Iteration 149, loss = 0.11224127\n",
            "Iteration 150, loss = 0.11211617\n",
            "Iteration 151, loss = 0.11197728\n",
            "Iteration 152, loss = 0.11240077\n",
            "Iteration 153, loss = 0.11149357\n",
            "Iteration 154, loss = 0.11261180\n",
            "Iteration 155, loss = 0.11368353\n",
            "Iteration 156, loss = 0.11279104\n",
            "Iteration 157, loss = 0.11026976\n",
            "Iteration 158, loss = 0.11118565\n",
            "Iteration 159, loss = 0.11103449\n",
            "Iteration 160, loss = 0.11088322\n",
            "Iteration 161, loss = 0.11001078\n",
            "Iteration 162, loss = 0.11069799\n",
            "Iteration 163, loss = 0.11049532\n",
            "Iteration 164, loss = 0.11037124\n",
            "Iteration 165, loss = 0.11013674\n",
            "Iteration 166, loss = 0.10990082\n",
            "Iteration 167, loss = 0.11007533\n",
            "Iteration 168, loss = 0.10977035\n",
            "Iteration 169, loss = 0.10951603\n",
            "Iteration 170, loss = 0.10938517\n",
            "Iteration 171, loss = 0.10929430\n",
            "Iteration 172, loss = 0.10913252\n",
            "Iteration 173, loss = 0.10912678\n",
            "Iteration 174, loss = 0.10906392\n",
            "Iteration 175, loss = 0.10785041\n",
            "Iteration 176, loss = 0.11020132\n",
            "Iteration 177, loss = 0.10778945\n",
            "Iteration 178, loss = 0.10572459\n",
            "Iteration 179, loss = 0.10505124\n",
            "Iteration 180, loss = 0.10476181\n",
            "Iteration 181, loss = 0.10433599\n",
            "Iteration 182, loss = 0.10438214\n",
            "Iteration 183, loss = 0.10398007\n",
            "Iteration 184, loss = 0.10409709\n",
            "Iteration 185, loss = 0.10325097\n",
            "Iteration 186, loss = 0.10403047\n",
            "Iteration 187, loss = 0.10374908\n",
            "Iteration 188, loss = 0.10283806\n",
            "Iteration 189, loss = 0.10280117\n",
            "Iteration 190, loss = 0.10285366\n",
            "Iteration 191, loss = 0.10312266\n",
            "Iteration 192, loss = 0.10243717\n",
            "Iteration 193, loss = 0.10294608\n",
            "Iteration 194, loss = 0.10501796\n",
            "Iteration 195, loss = 0.11497000\n",
            "Iteration 196, loss = 0.10748354\n",
            "Iteration 197, loss = 0.10366431\n",
            "Iteration 198, loss = 0.10255201\n",
            "Iteration 199, loss = 0.10300179\n",
            "Iteration 200, loss = 0.10357398\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.70791443\n",
            "Iteration 2, loss = 1.14719436\n",
            "Iteration 3, loss = 1.00780844\n",
            "Iteration 4, loss = 0.84045532\n",
            "Iteration 5, loss = 0.78107674\n",
            "Iteration 6, loss = 0.86912214\n",
            "Iteration 7, loss = 0.75669941\n",
            "Iteration 8, loss = 0.85855916\n",
            "Iteration 9, loss = 0.85675229\n",
            "Iteration 10, loss = 0.73103949\n",
            "Iteration 11, loss = 0.66101900\n",
            "Iteration 12, loss = 0.63360974\n",
            "Iteration 13, loss = 0.67490318\n",
            "Iteration 14, loss = 0.62072829\n",
            "Iteration 15, loss = 0.60107482\n",
            "Iteration 16, loss = 0.57541331\n",
            "Iteration 17, loss = 0.56811830\n",
            "Iteration 18, loss = 0.53720529\n",
            "Iteration 19, loss = 0.64136283\n",
            "Iteration 20, loss = 0.67930286\n",
            "Iteration 21, loss = 0.52974771\n",
            "Iteration 22, loss = 0.63448788\n",
            "Iteration 23, loss = 0.58848501\n",
            "Iteration 24, loss = 0.59977360\n",
            "Iteration 25, loss = 0.45643552\n",
            "Iteration 26, loss = 0.46246028\n",
            "Iteration 27, loss = 0.47847951\n",
            "Iteration 28, loss = 0.57296160\n",
            "Iteration 29, loss = 0.41349513\n",
            "Iteration 30, loss = 0.52636137\n",
            "Iteration 31, loss = 0.45034103\n",
            "Iteration 32, loss = 0.51258792\n",
            "Iteration 33, loss = 0.45897795\n",
            "Iteration 34, loss = 0.54274492\n",
            "Iteration 35, loss = 0.52931765\n",
            "Iteration 36, loss = 0.54874637\n",
            "Iteration 37, loss = 0.43140746\n",
            "Iteration 38, loss = 0.51236538\n",
            "Iteration 39, loss = 0.50160018\n",
            "Iteration 40, loss = 0.44238899\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000200\n",
            "Iteration 41, loss = 0.49393626\n",
            "Iteration 42, loss = 0.36000905\n",
            "Iteration 43, loss = 0.34983946\n",
            "Iteration 44, loss = 0.34546051\n",
            "Iteration 45, loss = 0.35404098\n",
            "Iteration 46, loss = 0.33987624\n",
            "Iteration 47, loss = 0.32816008\n",
            "Iteration 48, loss = 0.32688677\n",
            "Iteration 49, loss = 0.32650735\n",
            "Iteration 50, loss = 0.31935875\n",
            "Iteration 51, loss = 0.31747284\n",
            "Iteration 52, loss = 0.34006514\n",
            "Iteration 53, loss = 0.32159003\n",
            "Iteration 54, loss = 0.31618000\n",
            "Iteration 55, loss = 0.30590233\n",
            "Iteration 56, loss = 0.31107641\n",
            "Iteration 57, loss = 0.31079869\n",
            "Iteration 58, loss = 0.29252697\n",
            "Iteration 59, loss = 0.28529157\n",
            "Iteration 60, loss = 0.28235792\n",
            "Iteration 61, loss = 0.27802372\n",
            "Iteration 62, loss = 0.27253316\n",
            "Iteration 63, loss = 0.27008497\n",
            "Iteration 64, loss = 0.27023951\n",
            "Iteration 65, loss = 0.26156931\n",
            "Iteration 66, loss = 0.26356369\n",
            "Iteration 67, loss = 0.25137102\n",
            "Iteration 68, loss = 0.24707089\n",
            "Iteration 69, loss = 0.25307572\n",
            "Iteration 70, loss = 0.24705762\n",
            "Iteration 71, loss = 0.24392377\n",
            "Iteration 72, loss = 0.23214860\n",
            "Iteration 73, loss = 0.24794893\n",
            "Iteration 74, loss = 0.23641885\n",
            "Iteration 75, loss = 0.23129505\n",
            "Iteration 76, loss = 0.22947407\n",
            "Iteration 77, loss = 0.23158602\n",
            "Iteration 78, loss = 0.22506128\n",
            "Iteration 79, loss = 0.22737337\n",
            "Iteration 80, loss = 0.22837981\n",
            "Iteration 81, loss = 0.22129707\n",
            "Iteration 82, loss = 0.21254864\n",
            "Iteration 83, loss = 0.22223923\n",
            "Iteration 84, loss = 0.21225085\n",
            "Iteration 85, loss = 0.21150779\n",
            "Iteration 86, loss = 0.21266664\n",
            "Iteration 87, loss = 0.20644586\n",
            "Iteration 88, loss = 0.20852561\n",
            "Iteration 89, loss = 0.21281364\n",
            "Iteration 90, loss = 0.21633670\n",
            "Iteration 91, loss = 0.21128939\n",
            "Iteration 92, loss = 0.21464177\n",
            "Iteration 93, loss = 0.20781054\n",
            "Iteration 94, loss = 0.20452242\n",
            "Iteration 95, loss = 0.19961602\n",
            "Iteration 96, loss = 0.19750502\n",
            "Iteration 97, loss = 0.20565278\n",
            "Iteration 98, loss = 0.19495722\n",
            "Iteration 99, loss = 0.19737491\n",
            "Iteration 100, loss = 0.19448795\n",
            "Iteration 101, loss = 0.19401058\n",
            "Iteration 102, loss = 0.19557880\n",
            "Iteration 103, loss = 0.19635404\n",
            "Iteration 104, loss = 0.19091330\n",
            "Iteration 105, loss = 0.19042899\n",
            "Iteration 106, loss = 0.19764193\n",
            "Iteration 107, loss = 0.19026901\n",
            "Iteration 108, loss = 0.18966754\n",
            "Iteration 109, loss = 0.19076939\n",
            "Iteration 110, loss = 0.18861410\n",
            "Iteration 111, loss = 0.18817017\n",
            "Iteration 112, loss = 0.18566999\n",
            "Iteration 113, loss = 0.18639788\n",
            "Iteration 114, loss = 0.19492894\n",
            "Iteration 115, loss = 0.18728650\n",
            "Iteration 116, loss = 0.19524353\n",
            "Iteration 117, loss = 0.19466651\n",
            "Iteration 118, loss = 0.18320033\n",
            "Iteration 119, loss = 0.18623088\n",
            "Iteration 120, loss = 0.18700438\n",
            "Iteration 121, loss = 0.18027977\n",
            "Iteration 122, loss = 0.18483044\n",
            "Iteration 123, loss = 0.17953045\n",
            "Iteration 124, loss = 0.17854283\n",
            "Iteration 125, loss = 0.18158312\n",
            "Iteration 126, loss = 0.17573105\n",
            "Iteration 127, loss = 0.17827932\n",
            "Iteration 128, loss = 0.17585103\n",
            "Iteration 129, loss = 0.17766280\n",
            "Iteration 130, loss = 0.17372390\n",
            "Iteration 131, loss = 0.17001689\n",
            "Iteration 132, loss = 0.17792183\n",
            "Iteration 133, loss = 0.18588232\n",
            "Iteration 134, loss = 0.18017887\n",
            "Iteration 135, loss = 0.17351405\n",
            "Iteration 136, loss = 0.18574458\n",
            "Iteration 137, loss = 0.16595562\n",
            "Iteration 138, loss = 0.16797868\n",
            "Iteration 139, loss = 0.16528014\n",
            "Iteration 140, loss = 0.16533878\n",
            "Iteration 141, loss = 0.17039683\n",
            "Iteration 142, loss = 0.16223473\n",
            "Iteration 143, loss = 0.15866413\n",
            "Iteration 144, loss = 0.16749529\n",
            "Iteration 145, loss = 0.15911541\n",
            "Iteration 146, loss = 0.15768104\n",
            "Iteration 147, loss = 0.16088284\n",
            "Iteration 148, loss = 0.15705783\n",
            "Iteration 149, loss = 0.17482178\n",
            "Iteration 150, loss = 0.17580309\n",
            "Iteration 151, loss = 0.16006645\n",
            "Iteration 152, loss = 0.16308306\n",
            "Iteration 153, loss = 0.15532495\n",
            "Iteration 154, loss = 0.15432402\n",
            "Iteration 155, loss = 0.15830837\n",
            "Iteration 156, loss = 0.15641016\n",
            "Iteration 157, loss = 0.15435414\n",
            "Iteration 158, loss = 0.15265172\n",
            "Iteration 159, loss = 0.16064396\n",
            "Iteration 160, loss = 0.16349671\n",
            "Iteration 161, loss = 0.14959214\n",
            "Iteration 162, loss = 0.16379311\n",
            "Iteration 163, loss = 0.15180544\n",
            "Iteration 164, loss = 0.15136885\n",
            "Iteration 165, loss = 0.15407017\n",
            "Iteration 166, loss = 0.15334851\n",
            "Iteration 167, loss = 0.15077865\n",
            "Iteration 168, loss = 0.16066183\n",
            "Iteration 169, loss = 0.15067280\n",
            "Iteration 170, loss = 0.15369063\n",
            "Iteration 171, loss = 0.14666978\n",
            "Iteration 172, loss = 0.14891185\n",
            "Iteration 173, loss = 0.14642562\n",
            "Iteration 174, loss = 0.14553491\n",
            "Iteration 175, loss = 0.14937707\n",
            "Iteration 176, loss = 0.14610757\n",
            "Iteration 177, loss = 0.14556673\n",
            "Iteration 178, loss = 0.14355240\n",
            "Iteration 179, loss = 0.14750687\n",
            "Iteration 180, loss = 0.14407215\n",
            "Iteration 181, loss = 0.14213938\n",
            "Iteration 182, loss = 0.15264589\n",
            "Iteration 183, loss = 0.16225807\n",
            "Iteration 184, loss = 0.14294227\n",
            "Iteration 185, loss = 0.14144748\n",
            "Iteration 186, loss = 0.14531615\n",
            "Iteration 187, loss = 0.14301804\n",
            "Iteration 188, loss = 0.14025227\n",
            "Iteration 189, loss = 0.13949018\n",
            "Iteration 190, loss = 0.14058198\n",
            "Iteration 191, loss = 0.14463227\n",
            "Iteration 192, loss = 0.14180809\n",
            "Iteration 193, loss = 0.14329782\n",
            "Iteration 194, loss = 0.14103443\n",
            "Iteration 195, loss = 0.13926532\n",
            "Iteration 196, loss = 0.13912291\n",
            "Iteration 197, loss = 0.13849725\n",
            "Iteration 198, loss = 0.13796190\n",
            "Iteration 199, loss = 0.13759402\n",
            "Iteration 200, loss = 0.13760141\n",
            "Hidden layer structure: 10\n",
            "Best loss: 0.14399752376294395\n",
            "Training accuracy: 94.85547600106074\n",
            "Test accuracy: 91.48148148148148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.58741307\n",
            "Iteration 2, loss = 0.85271486\n",
            "Iteration 3, loss = 0.52415163\n",
            "Iteration 4, loss = 0.66332250\n",
            "Iteration 5, loss = 0.64014120\n",
            "Iteration 6, loss = 0.61914326\n",
            "Iteration 7, loss = 0.41799257\n",
            "Iteration 8, loss = 0.48545666\n",
            "Iteration 9, loss = 0.47460861\n",
            "Iteration 10, loss = 0.40443886\n",
            "Iteration 11, loss = 0.32966983\n",
            "Iteration 12, loss = 0.35117302\n",
            "Iteration 13, loss = 0.31853228\n",
            "Iteration 14, loss = 0.29586029\n",
            "Iteration 15, loss = 0.36708177\n",
            "Iteration 16, loss = 0.35992393\n",
            "Iteration 17, loss = 0.39787474\n",
            "Iteration 18, loss = 0.28341758\n",
            "Iteration 19, loss = 0.22659242\n",
            "Iteration 20, loss = 0.20677273\n",
            "Iteration 21, loss = 0.24396741\n",
            "Iteration 22, loss = 0.28952431\n",
            "Iteration 23, loss = 0.18324630\n",
            "Iteration 24, loss = 0.16828724\n",
            "Iteration 25, loss = 0.24839370\n",
            "Iteration 26, loss = 0.15457721\n",
            "Iteration 27, loss = 0.22684188\n",
            "Iteration 28, loss = 0.29570144\n",
            "Iteration 29, loss = 0.26471844\n",
            "Iteration 30, loss = 0.37503391\n",
            "Iteration 31, loss = 0.32625767\n",
            "Iteration 32, loss = 0.34629549\n",
            "Iteration 33, loss = 0.39816422\n",
            "Iteration 34, loss = 0.43802856\n",
            "Iteration 35, loss = 0.34806865\n",
            "Iteration 36, loss = 0.27245874\n",
            "Iteration 37, loss = 0.32381083\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000200\n",
            "Iteration 38, loss = 0.37261027\n",
            "Iteration 39, loss = 0.21216586\n",
            "Iteration 40, loss = 0.17480099\n",
            "Iteration 41, loss = 0.16234672\n",
            "Iteration 42, loss = 0.16641015\n",
            "Iteration 43, loss = 0.15296195\n",
            "Iteration 44, loss = 0.14680443\n",
            "Iteration 45, loss = 0.14179050\n",
            "Iteration 46, loss = 0.14153258\n",
            "Iteration 47, loss = 0.12541317\n",
            "Iteration 48, loss = 0.11840872\n",
            "Iteration 49, loss = 0.11607069\n",
            "Iteration 50, loss = 0.11726407\n",
            "Iteration 51, loss = 0.10815699\n",
            "Iteration 52, loss = 0.10601737\n",
            "Iteration 53, loss = 0.10077102\n",
            "Iteration 54, loss = 0.09863855\n",
            "Iteration 55, loss = 0.09740886\n",
            "Iteration 56, loss = 0.09642882\n",
            "Iteration 57, loss = 0.09585323\n",
            "Iteration 58, loss = 0.09500381\n",
            "Iteration 59, loss = 0.09366383\n",
            "Iteration 60, loss = 0.09301227\n",
            "Iteration 61, loss = 0.09216947\n",
            "Iteration 62, loss = 0.09110137\n",
            "Iteration 63, loss = 0.09036870\n",
            "Iteration 64, loss = 0.08964206\n",
            "Iteration 65, loss = 0.08922529\n",
            "Iteration 66, loss = 0.08840111\n",
            "Iteration 67, loss = 0.08800601\n",
            "Iteration 68, loss = 0.08735583\n",
            "Iteration 69, loss = 0.08655833\n",
            "Iteration 70, loss = 0.08627795\n",
            "Iteration 71, loss = 0.08545268\n",
            "Iteration 72, loss = 0.08511689\n",
            "Iteration 73, loss = 0.08457058\n",
            "Iteration 74, loss = 0.08409442\n",
            "Iteration 75, loss = 0.08365470\n",
            "Iteration 76, loss = 0.08326818\n",
            "Iteration 77, loss = 0.08287437\n",
            "Iteration 78, loss = 0.08248541\n",
            "Iteration 79, loss = 0.08199980\n",
            "Iteration 80, loss = 0.08156256\n",
            "Iteration 81, loss = 0.08121123\n",
            "Iteration 82, loss = 0.08082416\n",
            "Iteration 83, loss = 0.08039834\n",
            "Iteration 84, loss = 0.08025814\n",
            "Iteration 85, loss = 0.07967933\n",
            "Iteration 86, loss = 0.07939595\n",
            "Iteration 87, loss = 0.07900410\n",
            "Iteration 88, loss = 0.07847900\n",
            "Iteration 89, loss = 0.07787554\n",
            "Iteration 90, loss = 0.08037910\n",
            "Iteration 91, loss = 0.07680226\n",
            "Iteration 92, loss = 0.07642305\n",
            "Iteration 93, loss = 0.07581189\n",
            "Iteration 94, loss = 0.07538689\n",
            "Iteration 95, loss = 0.07509368\n",
            "Iteration 96, loss = 0.07487115\n",
            "Iteration 97, loss = 0.07457042\n",
            "Iteration 98, loss = 0.07432925\n",
            "Iteration 99, loss = 0.07461888\n",
            "Iteration 100, loss = 0.07404439\n",
            "Iteration 101, loss = 0.07444760\n",
            "Iteration 102, loss = 0.07359750\n",
            "Iteration 103, loss = 0.07225120\n",
            "Iteration 104, loss = 0.07260658\n",
            "Iteration 105, loss = 0.07135095\n",
            "Iteration 106, loss = 0.07103581\n",
            "Iteration 107, loss = 0.07116402\n",
            "Iteration 108, loss = 0.07052715\n",
            "Iteration 109, loss = 0.07012396\n",
            "Iteration 110, loss = 0.06999188\n",
            "Iteration 111, loss = 0.06963001\n",
            "Iteration 112, loss = 0.06948331\n",
            "Iteration 113, loss = 0.06915982\n",
            "Iteration 114, loss = 0.06899741\n",
            "Iteration 115, loss = 0.06872286\n",
            "Iteration 116, loss = 0.06848277\n",
            "Iteration 117, loss = 0.06838438\n",
            "Iteration 118, loss = 0.06824023\n",
            "Iteration 119, loss = 0.06798278\n",
            "Iteration 120, loss = 0.06729460\n",
            "Iteration 121, loss = 0.06689331\n",
            "Iteration 122, loss = 0.06654520\n",
            "Iteration 123, loss = 0.06600752\n",
            "Iteration 124, loss = 0.06535800\n",
            "Iteration 125, loss = 0.06546483\n",
            "Iteration 126, loss = 0.06509061\n",
            "Iteration 127, loss = 0.06328477\n",
            "Iteration 128, loss = 0.06325072\n",
            "Iteration 129, loss = 0.06296609\n",
            "Iteration 130, loss = 0.06265923\n",
            "Iteration 131, loss = 0.06243823\n",
            "Iteration 132, loss = 0.06225129\n",
            "Iteration 133, loss = 0.06194005\n",
            "Iteration 134, loss = 0.06185669\n",
            "Iteration 135, loss = 0.06125106\n",
            "Iteration 136, loss = 0.06111112\n",
            "Iteration 137, loss = 0.06011306\n",
            "Iteration 138, loss = 0.06692908\n",
            "Iteration 139, loss = 0.06127460\n",
            "Iteration 140, loss = 0.05964340\n",
            "Iteration 141, loss = 0.05915084\n",
            "Iteration 142, loss = 0.05879669\n",
            "Iteration 143, loss = 0.05861523\n",
            "Iteration 144, loss = 0.05834645\n",
            "Iteration 145, loss = 0.05815626\n",
            "Iteration 146, loss = 0.05801226\n",
            "Iteration 147, loss = 0.05781567\n",
            "Iteration 148, loss = 0.05768395\n",
            "Iteration 149, loss = 0.05746846\n",
            "Iteration 150, loss = 0.05729058\n",
            "Iteration 151, loss = 0.05713167\n",
            "Iteration 152, loss = 0.05696666\n",
            "Iteration 153, loss = 0.05680162\n",
            "Iteration 154, loss = 0.05658449\n",
            "Iteration 155, loss = 0.05635439\n",
            "Iteration 156, loss = 0.05624028\n",
            "Iteration 157, loss = 0.05606222\n",
            "Iteration 158, loss = 0.05587368\n",
            "Iteration 159, loss = 0.05577877\n",
            "Iteration 160, loss = 0.05556974\n",
            "Iteration 161, loss = 0.05543748\n",
            "Iteration 162, loss = 0.05529181\n",
            "Iteration 163, loss = 0.05517629\n",
            "Iteration 164, loss = 0.05497962\n",
            "Iteration 165, loss = 0.05485118\n",
            "Iteration 166, loss = 0.05460967\n",
            "Iteration 167, loss = 0.05237123\n",
            "Iteration 168, loss = 0.05211932\n",
            "Iteration 169, loss = 0.05124457\n",
            "Iteration 170, loss = 0.05076449\n",
            "Iteration 171, loss = 0.05054193\n",
            "Iteration 172, loss = 0.05001220\n",
            "Iteration 173, loss = 0.04969678\n",
            "Iteration 174, loss = 0.04949908\n",
            "Iteration 175, loss = 0.04931667\n",
            "Iteration 176, loss = 0.04910830\n",
            "Iteration 177, loss = 0.04891358\n",
            "Iteration 178, loss = 0.04876474\n",
            "Iteration 179, loss = 0.04861852\n",
            "Iteration 180, loss = 0.04845543\n",
            "Iteration 181, loss = 0.04830942\n",
            "Iteration 182, loss = 0.04819797\n",
            "Iteration 183, loss = 0.04805587\n",
            "Iteration 184, loss = 0.04792489\n",
            "Iteration 185, loss = 0.04785375\n",
            "Iteration 186, loss = 0.04764500\n",
            "Iteration 187, loss = 0.04752554\n",
            "Iteration 188, loss = 0.04739374\n",
            "Iteration 189, loss = 0.04726441\n",
            "Iteration 190, loss = 0.04720445\n",
            "Iteration 191, loss = 0.04687161\n",
            "Iteration 192, loss = 0.04675385\n",
            "Iteration 193, loss = 0.04657101\n",
            "Iteration 194, loss = 0.04645989\n",
            "Iteration 195, loss = 0.04634644\n",
            "Iteration 196, loss = 0.04618639\n",
            "Iteration 197, loss = 0.04607728\n",
            "Iteration 198, loss = 0.04601468\n",
            "Iteration 199, loss = 0.04591677\n",
            "Iteration 200, loss = 0.04588270\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.57449414\n",
            "Iteration 2, loss = 0.96601206\n",
            "Iteration 3, loss = 0.71704799\n",
            "Iteration 4, loss = 0.56016813\n",
            "Iteration 5, loss = 0.46103923\n",
            "Iteration 6, loss = 0.43749133\n",
            "Iteration 7, loss = 0.47036082\n",
            "Iteration 8, loss = 0.39669407\n",
            "Iteration 9, loss = 0.42127686\n",
            "Iteration 10, loss = 0.52902061\n",
            "Iteration 11, loss = 0.32302802\n",
            "Iteration 12, loss = 0.28758218\n",
            "Iteration 13, loss = 0.42499882\n",
            "Iteration 14, loss = 0.44696410\n",
            "Iteration 15, loss = 0.35120030\n",
            "Iteration 16, loss = 0.36748306\n",
            "Iteration 17, loss = 0.32576074\n",
            "Iteration 18, loss = 0.40780430\n",
            "Iteration 19, loss = 0.43276370\n",
            "Iteration 20, loss = 0.38532786\n",
            "Iteration 21, loss = 0.30808035\n",
            "Iteration 22, loss = 0.31607006\n",
            "Iteration 23, loss = 0.28626006\n",
            "Iteration 24, loss = 0.29369685\n",
            "Iteration 25, loss = 0.36368746\n",
            "Iteration 26, loss = 0.40118735\n",
            "Iteration 27, loss = 0.39633384\n",
            "Iteration 28, loss = 0.34593614\n",
            "Iteration 29, loss = 0.24408147\n",
            "Iteration 30, loss = 0.28482621\n",
            "Iteration 31, loss = 0.37734711\n",
            "Iteration 32, loss = 0.22431624\n",
            "Iteration 33, loss = 0.33099331\n",
            "Iteration 34, loss = 0.21401818\n",
            "Iteration 35, loss = 0.19648966\n",
            "Iteration 36, loss = 0.21759759\n",
            "Iteration 37, loss = 0.24279324\n",
            "Iteration 38, loss = 0.38234041\n",
            "Iteration 39, loss = 0.37717803\n",
            "Iteration 40, loss = 0.23614498\n",
            "Iteration 41, loss = 0.15213265\n",
            "Iteration 42, loss = 0.22321251\n",
            "Iteration 43, loss = 0.22155428\n",
            "Iteration 44, loss = 0.20239614\n",
            "Iteration 45, loss = 0.22775251\n",
            "Iteration 46, loss = 0.15772108\n",
            "Iteration 47, loss = 0.12203558\n",
            "Iteration 48, loss = 0.14500717\n",
            "Iteration 49, loss = 0.12661147\n",
            "Iteration 50, loss = 0.11844965\n",
            "Iteration 51, loss = 0.10524519\n",
            "Iteration 52, loss = 0.13772781\n",
            "Iteration 53, loss = 0.21596940\n",
            "Iteration 54, loss = 0.17794711\n",
            "Iteration 55, loss = 0.14746073\n",
            "Iteration 56, loss = 0.14131927\n",
            "Iteration 57, loss = 0.19550132\n",
            "Iteration 58, loss = 0.17692583\n",
            "Iteration 59, loss = 0.17843424\n",
            "Iteration 60, loss = 0.13750856\n",
            "Iteration 61, loss = 0.20666810\n",
            "Iteration 62, loss = 0.16767907\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000200\n",
            "Iteration 63, loss = 0.10004330\n",
            "Iteration 64, loss = 0.09691912\n",
            "Iteration 65, loss = 0.09350479\n",
            "Iteration 66, loss = 0.09957105\n",
            "Iteration 67, loss = 0.09516093\n",
            "Iteration 68, loss = 0.09392799\n",
            "Iteration 69, loss = 0.09171157\n",
            "Iteration 70, loss = 0.09072151\n",
            "Iteration 71, loss = 0.09045846\n",
            "Iteration 72, loss = 0.08866196\n",
            "Iteration 73, loss = 0.08772554\n",
            "Iteration 74, loss = 0.08677691\n",
            "Iteration 75, loss = 0.08637244\n",
            "Iteration 76, loss = 0.08474187\n",
            "Iteration 77, loss = 0.08537298\n",
            "Iteration 78, loss = 0.08370694\n",
            "Iteration 79, loss = 0.08309968\n",
            "Iteration 80, loss = 0.08241770\n",
            "Iteration 81, loss = 0.08226971\n",
            "Iteration 82, loss = 0.08167512\n",
            "Iteration 83, loss = 0.08260086\n",
            "Iteration 84, loss = 0.08108644\n",
            "Iteration 85, loss = 0.08083313\n",
            "Iteration 86, loss = 0.08046554\n",
            "Iteration 87, loss = 0.07996336\n",
            "Iteration 88, loss = 0.07941248\n",
            "Iteration 89, loss = 0.08034138\n",
            "Iteration 90, loss = 0.07945841\n",
            "Iteration 91, loss = 0.07930903\n",
            "Iteration 92, loss = 0.07872288\n",
            "Iteration 93, loss = 0.07837392\n",
            "Iteration 94, loss = 0.07777334\n",
            "Iteration 95, loss = 0.07730927\n",
            "Iteration 96, loss = 0.07671348\n",
            "Iteration 97, loss = 0.07918589\n",
            "Iteration 98, loss = 0.07774057\n",
            "Iteration 99, loss = 0.07416103\n",
            "Iteration 100, loss = 0.07624777\n",
            "Iteration 101, loss = 0.07534894\n",
            "Iteration 102, loss = 0.07523272\n",
            "Iteration 103, loss = 0.07067107\n",
            "Iteration 104, loss = 0.07002183\n",
            "Iteration 105, loss = 0.08059808\n",
            "Iteration 106, loss = 0.07550679\n",
            "Iteration 107, loss = 0.06765331\n",
            "Iteration 108, loss = 0.06628442\n",
            "Iteration 109, loss = 0.06814437\n",
            "Iteration 110, loss = 0.06434844\n",
            "Iteration 111, loss = 0.06346336\n",
            "Iteration 112, loss = 0.06337198\n",
            "Iteration 113, loss = 0.06240717\n",
            "Iteration 114, loss = 0.06122464\n",
            "Iteration 115, loss = 0.06118128\n",
            "Iteration 116, loss = 0.06069184\n",
            "Iteration 117, loss = 0.06059426\n",
            "Iteration 118, loss = 0.06057089\n",
            "Iteration 119, loss = 0.06008480\n",
            "Iteration 120, loss = 0.06014985\n",
            "Iteration 121, loss = 0.06014440\n",
            "Iteration 122, loss = 0.05971981\n",
            "Iteration 123, loss = 0.05977845\n",
            "Iteration 124, loss = 0.05960795\n",
            "Iteration 125, loss = 0.05951520\n",
            "Iteration 126, loss = 0.05921605\n",
            "Iteration 127, loss = 0.05932477\n",
            "Iteration 128, loss = 0.05910164\n",
            "Iteration 129, loss = 0.05888040\n",
            "Iteration 130, loss = 0.05886482\n",
            "Iteration 131, loss = 0.05873802\n",
            "Iteration 132, loss = 0.05837443\n",
            "Iteration 133, loss = 0.05836680\n",
            "Iteration 134, loss = 0.05772310\n",
            "Iteration 135, loss = 0.05788732\n",
            "Iteration 136, loss = 0.05749646\n",
            "Iteration 137, loss = 0.05765608\n",
            "Iteration 138, loss = 0.05737148\n",
            "Iteration 139, loss = 0.05735734\n",
            "Iteration 140, loss = 0.05708449\n",
            "Iteration 141, loss = 0.05711455\n",
            "Iteration 142, loss = 0.05670241\n",
            "Iteration 143, loss = 0.05589429\n",
            "Iteration 144, loss = 0.05551534\n",
            "Iteration 145, loss = 0.05563612\n",
            "Iteration 146, loss = 0.05525312\n",
            "Iteration 147, loss = 0.05539021\n",
            "Iteration 148, loss = 0.05520735\n",
            "Iteration 149, loss = 0.05489126\n",
            "Iteration 150, loss = 0.05490561\n",
            "Iteration 151, loss = 0.05486214\n",
            "Iteration 152, loss = 0.05469511\n",
            "Iteration 153, loss = 0.05472052\n",
            "Iteration 154, loss = 0.05436746\n",
            "Iteration 155, loss = 0.05444714\n",
            "Iteration 156, loss = 0.05440230\n",
            "Iteration 157, loss = 0.05408282\n",
            "Iteration 158, loss = 0.05417153\n",
            "Iteration 159, loss = 0.05396237\n",
            "Iteration 160, loss = 0.05412980\n",
            "Iteration 161, loss = 0.05399527\n",
            "Iteration 162, loss = 0.05362942\n",
            "Iteration 163, loss = 0.05372977\n",
            "Iteration 164, loss = 0.05375685\n",
            "Iteration 165, loss = 0.05337596\n",
            "Iteration 166, loss = 0.05340942\n",
            "Iteration 167, loss = 0.05360270\n",
            "Iteration 168, loss = 0.05339431\n",
            "Iteration 169, loss = 0.05323280\n",
            "Iteration 170, loss = 0.05333214\n",
            "Iteration 171, loss = 0.05313236\n",
            "Iteration 172, loss = 0.05290129\n",
            "Iteration 173, loss = 0.05311352\n",
            "Iteration 174, loss = 0.05291810\n",
            "Iteration 175, loss = 0.05282601\n",
            "Iteration 176, loss = 0.05289260\n",
            "Iteration 177, loss = 0.05272011\n",
            "Iteration 178, loss = 0.05257333\n",
            "Iteration 179, loss = 0.05267869\n",
            "Iteration 180, loss = 0.05254256\n",
            "Iteration 181, loss = 0.05225458\n",
            "Iteration 182, loss = 0.05225743\n",
            "Iteration 183, loss = 0.05238739\n",
            "Iteration 184, loss = 0.05211893\n",
            "Iteration 185, loss = 0.05230418\n",
            "Iteration 186, loss = 0.05191698\n",
            "Iteration 187, loss = 0.05195321\n",
            "Iteration 188, loss = 0.05208014\n",
            "Iteration 189, loss = 0.05170942\n",
            "Iteration 190, loss = 0.05183105\n",
            "Iteration 191, loss = 0.05173233\n",
            "Iteration 192, loss = 0.05173623\n",
            "Iteration 193, loss = 0.05138435\n",
            "Iteration 194, loss = 0.05147515\n",
            "Iteration 195, loss = 0.05109864\n",
            "Iteration 196, loss = 0.05094655\n",
            "Iteration 197, loss = 0.05108792\n",
            "Iteration 198, loss = 0.05081234\n",
            "Iteration 199, loss = 0.05092360\n",
            "Iteration 200, loss = 0.05075628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.60347597\n",
            "Iteration 2, loss = 0.92429965\n",
            "Iteration 3, loss = 0.63359675\n",
            "Iteration 4, loss = 0.53825318\n",
            "Iteration 5, loss = 0.52930283\n",
            "Iteration 6, loss = 0.47128536\n",
            "Iteration 7, loss = 0.48237744\n",
            "Iteration 8, loss = 0.44719114\n",
            "Iteration 9, loss = 0.36580026\n",
            "Iteration 10, loss = 0.30649224\n",
            "Iteration 11, loss = 0.37077751\n",
            "Iteration 12, loss = 0.36241510\n",
            "Iteration 13, loss = 0.31985613\n",
            "Iteration 14, loss = 0.43105832\n",
            "Iteration 15, loss = 0.40469468\n",
            "Iteration 16, loss = 0.40770666\n",
            "Iteration 17, loss = 0.46199476\n",
            "Iteration 18, loss = 0.43666357\n",
            "Iteration 19, loss = 0.38431381\n",
            "Iteration 20, loss = 0.44157944\n",
            "Iteration 21, loss = 0.37173757\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000200\n",
            "Iteration 22, loss = 0.34820251\n",
            "Iteration 23, loss = 0.27705530\n",
            "Iteration 24, loss = 0.23846523\n",
            "Iteration 25, loss = 0.23216912\n",
            "Iteration 26, loss = 0.19653631\n",
            "Iteration 27, loss = 0.20209299\n",
            "Iteration 28, loss = 0.19495670\n",
            "Iteration 29, loss = 0.19392186\n",
            "Iteration 30, loss = 0.17702850\n",
            "Iteration 31, loss = 0.16579006\n",
            "Iteration 32, loss = 0.15744189\n",
            "Iteration 33, loss = 0.16053762\n",
            "Iteration 34, loss = 0.15499515\n",
            "Iteration 35, loss = 0.16167860\n",
            "Iteration 36, loss = 0.13788044\n",
            "Iteration 37, loss = 0.13500185\n",
            "Iteration 38, loss = 0.13974609\n",
            "Iteration 39, loss = 0.12744003\n",
            "Iteration 40, loss = 0.12345372\n",
            "Iteration 41, loss = 0.12289741\n",
            "Iteration 42, loss = 0.11130351\n",
            "Iteration 43, loss = 0.11281517\n",
            "Iteration 44, loss = 0.10918973\n",
            "Iteration 45, loss = 0.11423302\n",
            "Iteration 46, loss = 0.10727288\n",
            "Iteration 47, loss = 0.10540209\n",
            "Iteration 48, loss = 0.10378638\n",
            "Iteration 49, loss = 0.10079614\n",
            "Iteration 50, loss = 0.10066992\n",
            "Iteration 51, loss = 0.10282575\n",
            "Iteration 52, loss = 0.09764649\n",
            "Iteration 53, loss = 0.09620306\n",
            "Iteration 54, loss = 0.09488237\n",
            "Iteration 55, loss = 0.09547119\n",
            "Iteration 56, loss = 0.09226795\n",
            "Iteration 57, loss = 0.09153205\n",
            "Iteration 58, loss = 0.08984017\n",
            "Iteration 59, loss = 0.08911441\n",
            "Iteration 60, loss = 0.08794913\n",
            "Iteration 61, loss = 0.08734812\n",
            "Iteration 62, loss = 0.08649224\n",
            "Iteration 63, loss = 0.08576059\n",
            "Iteration 64, loss = 0.08525672\n",
            "Iteration 65, loss = 0.08487371\n",
            "Iteration 66, loss = 0.08453110\n",
            "Iteration 67, loss = 0.08284394\n",
            "Iteration 68, loss = 0.08311488\n",
            "Iteration 69, loss = 0.08158894\n",
            "Iteration 70, loss = 0.08118855\n",
            "Iteration 71, loss = 0.07999889\n",
            "Iteration 72, loss = 0.07910821\n",
            "Iteration 73, loss = 0.07866786\n",
            "Iteration 74, loss = 0.07798279\n",
            "Iteration 75, loss = 0.07738778\n",
            "Iteration 76, loss = 0.07642530\n",
            "Iteration 77, loss = 0.07534575\n",
            "Iteration 78, loss = 0.07440072\n",
            "Iteration 79, loss = 0.07331812\n",
            "Iteration 80, loss = 0.07247063\n",
            "Iteration 81, loss = 0.07223456\n",
            "Iteration 82, loss = 0.07091955\n",
            "Iteration 83, loss = 0.07105647\n",
            "Iteration 84, loss = 0.07027120\n",
            "Iteration 85, loss = 0.06964763\n",
            "Iteration 86, loss = 0.06892109\n",
            "Iteration 87, loss = 0.06835202\n",
            "Iteration 88, loss = 0.06797352\n",
            "Iteration 89, loss = 0.06750235\n",
            "Iteration 90, loss = 0.06770332\n",
            "Iteration 91, loss = 0.06637034\n",
            "Iteration 92, loss = 0.06584884\n",
            "Iteration 93, loss = 0.06575359\n",
            "Iteration 94, loss = 0.06545892\n",
            "Iteration 95, loss = 0.06436702\n",
            "Iteration 96, loss = 0.06459041\n",
            "Iteration 97, loss = 0.06351097\n",
            "Iteration 98, loss = 0.06491966\n",
            "Iteration 99, loss = 0.06764388\n",
            "Iteration 100, loss = 0.06315229\n",
            "Iteration 101, loss = 0.06236908\n",
            "Iteration 102, loss = 0.06182159\n",
            "Iteration 103, loss = 0.06132618\n",
            "Iteration 104, loss = 0.06402814\n",
            "Iteration 105, loss = 0.06268486\n",
            "Iteration 106, loss = 0.06059835\n",
            "Iteration 107, loss = 0.06104658\n",
            "Iteration 108, loss = 0.05960339\n",
            "Iteration 109, loss = 0.05764913\n",
            "Iteration 110, loss = 0.05725905\n",
            "Iteration 111, loss = 0.05780835\n",
            "Iteration 112, loss = 0.05905319\n",
            "Iteration 113, loss = 0.05654705\n",
            "Iteration 114, loss = 0.05617220\n",
            "Iteration 115, loss = 0.05531994\n",
            "Iteration 116, loss = 0.05457959\n",
            "Iteration 117, loss = 0.05430592\n",
            "Iteration 118, loss = 0.05413346\n",
            "Iteration 119, loss = 0.05387803\n",
            "Iteration 120, loss = 0.05338763\n",
            "Iteration 121, loss = 0.05316397\n",
            "Iteration 122, loss = 0.05275518\n",
            "Iteration 123, loss = 0.05256247\n",
            "Iteration 124, loss = 0.05819640\n",
            "Iteration 125, loss = 0.06479950\n",
            "Iteration 126, loss = 0.05385143\n",
            "Iteration 127, loss = 0.05223806\n",
            "Iteration 128, loss = 0.05157777\n",
            "Iteration 129, loss = 0.05091803\n",
            "Iteration 130, loss = 0.05073009\n",
            "Iteration 131, loss = 0.05068770\n",
            "Iteration 132, loss = 0.05040568\n",
            "Iteration 133, loss = 0.04988423\n",
            "Iteration 134, loss = 0.04934492\n",
            "Iteration 135, loss = 0.04899504\n",
            "Iteration 136, loss = 0.04819010\n",
            "Iteration 137, loss = 0.04782702\n",
            "Iteration 138, loss = 0.05077011\n",
            "Iteration 139, loss = 0.04689806\n",
            "Iteration 140, loss = 0.04740807\n",
            "Iteration 141, loss = 0.04615996\n",
            "Iteration 142, loss = 0.04528685\n",
            "Iteration 143, loss = 0.04512945\n",
            "Iteration 144, loss = 0.04426220\n",
            "Iteration 145, loss = 0.04434097\n",
            "Iteration 146, loss = 0.04350643\n",
            "Iteration 147, loss = 0.04294767\n",
            "Iteration 148, loss = 0.04259847\n",
            "Iteration 149, loss = 0.04217488\n",
            "Iteration 150, loss = 0.04190458\n",
            "Iteration 151, loss = 0.04135279\n",
            "Iteration 152, loss = 0.04107884\n",
            "Iteration 153, loss = 0.04085751\n",
            "Iteration 154, loss = 0.04075314\n",
            "Iteration 155, loss = 0.04073899\n",
            "Iteration 156, loss = 0.04022709\n",
            "Iteration 157, loss = 0.03966503\n",
            "Iteration 158, loss = 0.03951557\n",
            "Iteration 159, loss = 0.03935786\n",
            "Iteration 160, loss = 0.03906191\n",
            "Iteration 161, loss = 0.03880490\n",
            "Iteration 162, loss = 0.03855942\n",
            "Iteration 163, loss = 0.03964424\n",
            "Iteration 164, loss = 0.03911971\n",
            "Iteration 165, loss = 0.03882308\n",
            "Iteration 166, loss = 0.03862236\n",
            "Iteration 167, loss = 0.03829885\n",
            "Iteration 168, loss = 0.03804076\n",
            "Iteration 169, loss = 0.03703903\n",
            "Iteration 170, loss = 0.03681613\n",
            "Iteration 171, loss = 0.03575260\n",
            "Iteration 172, loss = 0.03531310\n",
            "Iteration 173, loss = 0.03539164\n",
            "Iteration 174, loss = 0.03462854\n",
            "Iteration 175, loss = 0.03477719\n",
            "Iteration 176, loss = 0.03419939\n",
            "Iteration 177, loss = 0.03368537\n",
            "Iteration 178, loss = 0.03385099\n",
            "Iteration 179, loss = 0.03346555\n",
            "Iteration 180, loss = 0.03284019\n",
            "Iteration 181, loss = 0.03258494\n",
            "Iteration 182, loss = 0.03233430\n",
            "Iteration 183, loss = 0.03212421\n",
            "Iteration 184, loss = 0.03222836\n",
            "Iteration 185, loss = 0.03204381\n",
            "Iteration 186, loss = 0.03204204\n",
            "Iteration 187, loss = 0.03164233\n",
            "Iteration 188, loss = 0.03137428\n",
            "Iteration 189, loss = 0.03195752\n",
            "Iteration 190, loss = 0.03187592\n",
            "Iteration 191, loss = 0.03192442\n",
            "Iteration 192, loss = 0.03118132\n",
            "Iteration 193, loss = 0.03101923\n",
            "Iteration 194, loss = 0.03078712\n",
            "Iteration 195, loss = 0.03069475\n",
            "Iteration 196, loss = 0.03042037\n",
            "Iteration 197, loss = 0.03045972\n",
            "Iteration 198, loss = 0.03325248\n",
            "Iteration 199, loss = 0.03084322\n",
            "Iteration 200, loss = 0.03037113\n",
            "Hidden layer structure: 20\n",
            "Best loss: 0.04233670351939236\n",
            "Training accuracy: 99.09838239193847\n",
            "Test accuracy: 94.69135802469137\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.06410448\n",
            "Iteration 2, loss = 0.46959813\n",
            "Iteration 3, loss = 0.39534723\n",
            "Iteration 4, loss = 0.31452760\n",
            "Iteration 5, loss = 0.34590193\n",
            "Iteration 6, loss = 0.32787987\n",
            "Iteration 7, loss = 0.26464318\n",
            "Iteration 8, loss = 0.27197873\n",
            "Iteration 9, loss = 0.36423114\n",
            "Iteration 10, loss = 0.28149441\n",
            "Iteration 11, loss = 0.24020794\n",
            "Iteration 12, loss = 0.26422644\n",
            "Iteration 13, loss = 0.21366078\n",
            "Iteration 14, loss = 0.22307090\n",
            "Iteration 15, loss = 0.20726203\n",
            "Iteration 16, loss = 0.32113279\n",
            "Iteration 17, loss = 0.25786955\n",
            "Iteration 18, loss = 0.29334601\n",
            "Iteration 19, loss = 0.31311689\n",
            "Iteration 20, loss = 0.27437312\n",
            "Iteration 21, loss = 0.27072965\n",
            "Iteration 22, loss = 0.28289701\n",
            "Iteration 23, loss = 0.17086716\n",
            "Iteration 24, loss = 0.22705041\n",
            "Iteration 25, loss = 0.24450045\n",
            "Iteration 26, loss = 0.29437637\n",
            "Iteration 27, loss = 0.24622694\n",
            "Iteration 28, loss = 0.23027527\n",
            "Iteration 29, loss = 0.23947998\n",
            "Iteration 30, loss = 0.21932206\n",
            "Iteration 31, loss = 0.25119587\n",
            "Iteration 32, loss = 0.20551461\n",
            "Iteration 33, loss = 0.18483583\n",
            "Iteration 34, loss = 0.19850054\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000200\n",
            "Iteration 35, loss = 0.14857279\n",
            "Iteration 36, loss = 0.12051024\n",
            "Iteration 37, loss = 0.10724250\n",
            "Iteration 38, loss = 0.09720085\n",
            "Iteration 39, loss = 0.09359654\n",
            "Iteration 40, loss = 0.08804251\n",
            "Iteration 41, loss = 0.08314125\n",
            "Iteration 42, loss = 0.08230325\n",
            "Iteration 43, loss = 0.08087573\n",
            "Iteration 44, loss = 0.07896804\n",
            "Iteration 45, loss = 0.07626538\n",
            "Iteration 46, loss = 0.07674881\n",
            "Iteration 47, loss = 0.07112472\n",
            "Iteration 48, loss = 0.07010790\n",
            "Iteration 49, loss = 0.07078603\n",
            "Iteration 50, loss = 0.06729283\n",
            "Iteration 51, loss = 0.06699947\n",
            "Iteration 52, loss = 0.06491294\n",
            "Iteration 53, loss = 0.06275976\n",
            "Iteration 54, loss = 0.06077209\n",
            "Iteration 55, loss = 0.05969686\n",
            "Iteration 56, loss = 0.06091419\n",
            "Iteration 57, loss = 0.05700387\n",
            "Iteration 58, loss = 0.05606387\n",
            "Iteration 59, loss = 0.05540646\n",
            "Iteration 60, loss = 0.05474530\n",
            "Iteration 61, loss = 0.05386784\n",
            "Iteration 62, loss = 0.05234615\n",
            "Iteration 63, loss = 0.05792274\n",
            "Iteration 64, loss = 0.05154411\n",
            "Iteration 65, loss = 0.05030200\n",
            "Iteration 66, loss = 0.04854401\n",
            "Iteration 67, loss = 0.04764199\n",
            "Iteration 68, loss = 0.04699508\n",
            "Iteration 69, loss = 0.04644144\n",
            "Iteration 70, loss = 0.04609663\n",
            "Iteration 71, loss = 0.04553447\n",
            "Iteration 72, loss = 0.04523406\n",
            "Iteration 73, loss = 0.04467022\n",
            "Iteration 74, loss = 0.04420427\n",
            "Iteration 75, loss = 0.04367335\n",
            "Iteration 76, loss = 0.04321594\n",
            "Iteration 77, loss = 0.04285219\n",
            "Iteration 78, loss = 0.04239507\n",
            "Iteration 79, loss = 0.04194703\n",
            "Iteration 80, loss = 0.04127427\n",
            "Iteration 81, loss = 0.04087147\n",
            "Iteration 82, loss = 0.04051892\n",
            "Iteration 83, loss = 0.04011411\n",
            "Iteration 84, loss = 0.03984867\n",
            "Iteration 85, loss = 0.03958547\n",
            "Iteration 86, loss = 0.03933353\n",
            "Iteration 87, loss = 0.03900551\n",
            "Iteration 88, loss = 0.03871618\n",
            "Iteration 89, loss = 0.03838035\n",
            "Iteration 90, loss = 0.03808723\n",
            "Iteration 91, loss = 0.03772369\n",
            "Iteration 92, loss = 0.03749516\n",
            "Iteration 93, loss = 0.03717179\n",
            "Iteration 94, loss = 0.03699123\n",
            "Iteration 95, loss = 0.03660379\n",
            "Iteration 96, loss = 0.03645581\n",
            "Iteration 97, loss = 0.03617239\n",
            "Iteration 98, loss = 0.03597018\n",
            "Iteration 99, loss = 0.03567485\n",
            "Iteration 100, loss = 0.03544365\n",
            "Iteration 101, loss = 0.03529371\n",
            "Iteration 102, loss = 0.03510408\n",
            "Iteration 103, loss = 0.03492570\n",
            "Iteration 104, loss = 0.03476738\n",
            "Iteration 105, loss = 0.03457866\n",
            "Iteration 106, loss = 0.03439874\n",
            "Iteration 107, loss = 0.03423405\n",
            "Iteration 108, loss = 0.03411499\n",
            "Iteration 109, loss = 0.03389199\n",
            "Iteration 110, loss = 0.03385245\n",
            "Iteration 111, loss = 0.03361084\n",
            "Iteration 112, loss = 0.03350380\n",
            "Iteration 113, loss = 0.03337769\n",
            "Iteration 114, loss = 0.03321327\n",
            "Iteration 115, loss = 0.03310121\n",
            "Iteration 116, loss = 0.03293042\n",
            "Iteration 117, loss = 0.03279578\n",
            "Iteration 118, loss = 0.03261447\n",
            "Iteration 119, loss = 0.03252314\n",
            "Iteration 120, loss = 0.03232286\n",
            "Iteration 121, loss = 0.03215924\n",
            "Iteration 122, loss = 0.03211557\n",
            "Iteration 123, loss = 0.03199106\n",
            "Iteration 124, loss = 0.03184465\n",
            "Iteration 125, loss = 0.03172940\n",
            "Iteration 126, loss = 0.03158629\n",
            "Iteration 127, loss = 0.03147236\n",
            "Iteration 128, loss = 0.03135287\n",
            "Iteration 129, loss = 0.03122549\n",
            "Iteration 130, loss = 0.03112468\n",
            "Iteration 131, loss = 0.03098285\n",
            "Iteration 132, loss = 0.03086412\n",
            "Iteration 133, loss = 0.03076108\n",
            "Iteration 134, loss = 0.03062618\n",
            "Iteration 135, loss = 0.03054543\n",
            "Iteration 136, loss = 0.03036572\n",
            "Iteration 137, loss = 0.03029453\n",
            "Iteration 138, loss = 0.03019062\n",
            "Iteration 139, loss = 0.03007678\n",
            "Iteration 140, loss = 0.02994148\n",
            "Iteration 141, loss = 0.02981064\n",
            "Iteration 142, loss = 0.02978422\n",
            "Iteration 143, loss = 0.02964314\n",
            "Iteration 144, loss = 0.02955730\n",
            "Iteration 145, loss = 0.02943862\n",
            "Iteration 146, loss = 0.02934176\n",
            "Iteration 147, loss = 0.02926346\n",
            "Iteration 148, loss = 0.02913564\n",
            "Iteration 149, loss = 0.02902741\n",
            "Iteration 150, loss = 0.02892913\n",
            "Iteration 151, loss = 0.02885974\n",
            "Iteration 152, loss = 0.02873709\n",
            "Iteration 153, loss = 0.02865724\n",
            "Iteration 154, loss = 0.02858772\n",
            "Iteration 155, loss = 0.02846778\n",
            "Iteration 156, loss = 0.02838620\n",
            "Iteration 157, loss = 0.02826723\n",
            "Iteration 158, loss = 0.02821698\n",
            "Iteration 159, loss = 0.02809197\n",
            "Iteration 160, loss = 0.02801480\n",
            "Iteration 161, loss = 0.02785401\n",
            "Iteration 162, loss = 0.02773315\n",
            "Iteration 163, loss = 0.02764397\n",
            "Iteration 164, loss = 0.02757053\n",
            "Iteration 165, loss = 0.02742161\n",
            "Iteration 166, loss = 0.02735493\n",
            "Iteration 167, loss = 0.02728746\n",
            "Iteration 168, loss = 0.02719155\n",
            "Iteration 169, loss = 0.02712825\n",
            "Iteration 170, loss = 0.02704488\n",
            "Iteration 171, loss = 0.02688390\n",
            "Iteration 172, loss = 0.02675334\n",
            "Iteration 173, loss = 0.02644804\n",
            "Iteration 174, loss = 0.02611703\n",
            "Iteration 175, loss = 0.02588234\n",
            "Iteration 176, loss = 0.02579987\n",
            "Iteration 177, loss = 0.02564215\n",
            "Iteration 178, loss = 0.02507559\n",
            "Iteration 179, loss = 0.02452129\n",
            "Iteration 180, loss = 0.02440821\n",
            "Iteration 181, loss = 0.02421497\n",
            "Iteration 182, loss = 0.02416504\n",
            "Iteration 183, loss = 0.02406137\n",
            "Iteration 184, loss = 0.02396401\n",
            "Iteration 185, loss = 0.02382249\n",
            "Iteration 186, loss = 0.02372962\n",
            "Iteration 187, loss = 0.02358238\n",
            "Iteration 188, loss = 0.02353907\n",
            "Iteration 189, loss = 0.02342372\n",
            "Iteration 190, loss = 0.02335064\n",
            "Iteration 191, loss = 0.02320516\n",
            "Iteration 192, loss = 0.02307574\n",
            "Iteration 193, loss = 0.02302366\n",
            "Iteration 194, loss = 0.02289174\n",
            "Iteration 195, loss = 0.02273739\n",
            "Iteration 196, loss = 0.02267260\n",
            "Iteration 197, loss = 0.02252408\n",
            "Iteration 198, loss = 0.02245734\n",
            "Iteration 199, loss = 0.02237051\n",
            "Iteration 200, loss = 0.02226061\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.09049480\n",
            "Iteration 2, loss = 0.55032083\n",
            "Iteration 3, loss = 0.38981153\n",
            "Iteration 4, loss = 0.36462262\n",
            "Iteration 5, loss = 0.31127855\n",
            "Iteration 6, loss = 0.29524766\n",
            "Iteration 7, loss = 0.29983027\n",
            "Iteration 8, loss = 0.23629971\n",
            "Iteration 9, loss = 0.26986467\n",
            "Iteration 10, loss = 0.31552254\n",
            "Iteration 11, loss = 0.28802570\n",
            "Iteration 12, loss = 0.26579151\n",
            "Iteration 13, loss = 0.32279532\n",
            "Iteration 14, loss = 0.31813653\n",
            "Iteration 15, loss = 0.25374393\n",
            "Iteration 16, loss = 0.32121909\n",
            "Iteration 17, loss = 0.28842931\n",
            "Iteration 18, loss = 0.26821829\n",
            "Iteration 19, loss = 0.29194714\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000200\n",
            "Iteration 20, loss = 0.19123462\n",
            "Iteration 21, loss = 0.15264767\n",
            "Iteration 22, loss = 0.12607633\n",
            "Iteration 23, loss = 0.11627355\n",
            "Iteration 24, loss = 0.10543300\n",
            "Iteration 25, loss = 0.10422031\n",
            "Iteration 26, loss = 0.09616669\n",
            "Iteration 27, loss = 0.08761055\n",
            "Iteration 28, loss = 0.08258045\n",
            "Iteration 29, loss = 0.08052794\n",
            "Iteration 30, loss = 0.07742449\n",
            "Iteration 31, loss = 0.07489303\n",
            "Iteration 32, loss = 0.07280580\n",
            "Iteration 33, loss = 0.07158309\n",
            "Iteration 34, loss = 0.07110255\n",
            "Iteration 35, loss = 0.07047121\n",
            "Iteration 36, loss = 0.06819677\n",
            "Iteration 37, loss = 0.06709471\n",
            "Iteration 38, loss = 0.06480941\n",
            "Iteration 39, loss = 0.06366256\n",
            "Iteration 40, loss = 0.06123660\n",
            "Iteration 41, loss = 0.06047204\n",
            "Iteration 42, loss = 0.05942403\n",
            "Iteration 43, loss = 0.05856045\n",
            "Iteration 44, loss = 0.05787086\n",
            "Iteration 45, loss = 0.05732860\n",
            "Iteration 46, loss = 0.05678474\n",
            "Iteration 47, loss = 0.05591139\n",
            "Iteration 48, loss = 0.05579897\n",
            "Iteration 49, loss = 0.05363512\n",
            "Iteration 50, loss = 0.05252454\n",
            "Iteration 51, loss = 0.05143246\n",
            "Iteration 52, loss = 0.05144303\n",
            "Iteration 53, loss = 0.04966455\n",
            "Iteration 54, loss = 0.04960327\n",
            "Iteration 55, loss = 0.04890445\n",
            "Iteration 56, loss = 0.04770473\n",
            "Iteration 57, loss = 0.04684947\n",
            "Iteration 58, loss = 0.04620336\n",
            "Iteration 59, loss = 0.04585921\n",
            "Iteration 60, loss = 0.04533941\n",
            "Iteration 61, loss = 0.04497636\n",
            "Iteration 62, loss = 0.04473028\n",
            "Iteration 63, loss = 0.04414128\n",
            "Iteration 64, loss = 0.04387270\n",
            "Iteration 65, loss = 0.04321670\n",
            "Iteration 66, loss = 0.04287594\n",
            "Iteration 67, loss = 0.04227380\n",
            "Iteration 68, loss = 0.04185035\n",
            "Iteration 69, loss = 0.04152593\n",
            "Iteration 70, loss = 0.04104029\n",
            "Iteration 71, loss = 0.04091256\n",
            "Iteration 72, loss = 0.04061924\n",
            "Iteration 73, loss = 0.04046018\n",
            "Iteration 74, loss = 0.03999894\n",
            "Iteration 75, loss = 0.03968948\n",
            "Iteration 76, loss = 0.03963961\n",
            "Iteration 77, loss = 0.03918426\n",
            "Iteration 78, loss = 0.03886153\n",
            "Iteration 79, loss = 0.03857486\n",
            "Iteration 80, loss = 0.03841550\n",
            "Iteration 81, loss = 0.03807394\n",
            "Iteration 82, loss = 0.03785343\n",
            "Iteration 83, loss = 0.03717491\n",
            "Iteration 84, loss = 0.03977976\n",
            "Iteration 85, loss = 0.03743591\n",
            "Iteration 86, loss = 0.03711951\n",
            "Iteration 87, loss = 0.03572687\n",
            "Iteration 88, loss = 0.03479251\n",
            "Iteration 89, loss = 0.03454830\n",
            "Iteration 90, loss = 0.03405621\n",
            "Iteration 91, loss = 0.03385805\n",
            "Iteration 92, loss = 0.03367667\n",
            "Iteration 93, loss = 0.03344867\n",
            "Iteration 94, loss = 0.03321432\n",
            "Iteration 95, loss = 0.03306005\n",
            "Iteration 96, loss = 0.03285760\n",
            "Iteration 97, loss = 0.03266572\n",
            "Iteration 98, loss = 0.03252382\n",
            "Iteration 99, loss = 0.03223790\n",
            "Iteration 100, loss = 0.03212631\n",
            "Iteration 101, loss = 0.03198926\n",
            "Iteration 102, loss = 0.03177692\n",
            "Iteration 103, loss = 0.03165559\n",
            "Iteration 104, loss = 0.03147743\n",
            "Iteration 105, loss = 0.03134160\n",
            "Iteration 106, loss = 0.03111664\n",
            "Iteration 107, loss = 0.03093312\n",
            "Iteration 108, loss = 0.03080386\n",
            "Iteration 109, loss = 0.03056489\n",
            "Iteration 110, loss = 0.03041441\n",
            "Iteration 111, loss = 0.03025041\n",
            "Iteration 112, loss = 0.03007635\n",
            "Iteration 113, loss = 0.02989936\n",
            "Iteration 114, loss = 0.02972046\n",
            "Iteration 115, loss = 0.02957841\n",
            "Iteration 116, loss = 0.02938130\n",
            "Iteration 117, loss = 0.02925410\n",
            "Iteration 118, loss = 0.02904738\n",
            "Iteration 119, loss = 0.02899710\n",
            "Iteration 120, loss = 0.02925056\n",
            "Iteration 121, loss = 0.03048095\n",
            "Iteration 122, loss = 0.02867891\n",
            "Iteration 123, loss = 0.02843158\n",
            "Iteration 124, loss = 0.02827233\n",
            "Iteration 125, loss = 0.02805794\n",
            "Iteration 126, loss = 0.02787997\n",
            "Iteration 127, loss = 0.02779595\n",
            "Iteration 128, loss = 0.02751753\n",
            "Iteration 129, loss = 0.02745664\n",
            "Iteration 130, loss = 0.02711474\n",
            "Iteration 131, loss = 0.02724212\n",
            "Iteration 132, loss = 0.02712663\n",
            "Iteration 133, loss = 0.02665668\n",
            "Iteration 134, loss = 0.02646296\n",
            "Iteration 135, loss = 0.02624877\n",
            "Iteration 136, loss = 0.02600302\n",
            "Iteration 137, loss = 0.02597148\n",
            "Iteration 138, loss = 0.02576901\n",
            "Iteration 139, loss = 0.02568070\n",
            "Iteration 140, loss = 0.02551756\n",
            "Iteration 141, loss = 0.02540646\n",
            "Iteration 142, loss = 0.02531900\n",
            "Iteration 143, loss = 0.02515073\n",
            "Iteration 144, loss = 0.02499839\n",
            "Iteration 145, loss = 0.02488323\n",
            "Iteration 146, loss = 0.02470739\n",
            "Iteration 147, loss = 0.02455957\n",
            "Iteration 148, loss = 0.02440766\n",
            "Iteration 149, loss = 0.02427675\n",
            "Iteration 150, loss = 0.02417902\n",
            "Iteration 151, loss = 0.02409465\n",
            "Iteration 152, loss = 0.02393417\n",
            "Iteration 153, loss = 0.02382472\n",
            "Iteration 154, loss = 0.02365526\n",
            "Iteration 155, loss = 0.02351065\n",
            "Iteration 156, loss = 0.02341064\n",
            "Iteration 157, loss = 0.02324790\n",
            "Iteration 158, loss = 0.02309723\n",
            "Iteration 159, loss = 0.02299421\n",
            "Iteration 160, loss = 0.02285195\n",
            "Iteration 161, loss = 0.02272399\n",
            "Iteration 162, loss = 0.02252380\n",
            "Iteration 163, loss = 0.02243665\n",
            "Iteration 164, loss = 0.02235873\n",
            "Iteration 165, loss = 0.02223166\n",
            "Iteration 166, loss = 0.02212547\n",
            "Iteration 167, loss = 0.02203544\n",
            "Iteration 168, loss = 0.02182702\n",
            "Iteration 169, loss = 0.02175212\n",
            "Iteration 170, loss = 0.02175899\n",
            "Iteration 171, loss = 0.02157652\n",
            "Iteration 172, loss = 0.02301428\n",
            "Iteration 173, loss = 0.02012200\n",
            "Iteration 174, loss = 0.02000115\n",
            "Iteration 175, loss = 0.01983377\n",
            "Iteration 176, loss = 0.01963048\n",
            "Iteration 177, loss = 0.01939617\n",
            "Iteration 178, loss = 0.01936057\n",
            "Iteration 179, loss = 0.01933253\n",
            "Iteration 180, loss = 0.02044544\n",
            "Iteration 181, loss = 0.01887794\n",
            "Iteration 182, loss = 0.01846599\n",
            "Iteration 183, loss = 0.01829497\n",
            "Iteration 184, loss = 0.01815138\n",
            "Iteration 185, loss = 0.01807847\n",
            "Iteration 186, loss = 0.01786871\n",
            "Iteration 187, loss = 0.01763957\n",
            "Iteration 188, loss = 0.01751139\n",
            "Iteration 189, loss = 0.01741578\n",
            "Iteration 190, loss = 0.01733140\n",
            "Iteration 191, loss = 0.01721486\n",
            "Iteration 192, loss = 0.01703945\n",
            "Iteration 193, loss = 0.01692747\n",
            "Iteration 194, loss = 0.01686112\n",
            "Iteration 195, loss = 0.01673783\n",
            "Iteration 196, loss = 0.01669609\n",
            "Iteration 197, loss = 0.01658837\n",
            "Iteration 198, loss = 0.01649064\n",
            "Iteration 199, loss = 0.01636342\n",
            "Iteration 200, loss = 0.01628407\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.03890052\n",
            "Iteration 2, loss = 0.45624861\n",
            "Iteration 3, loss = 0.35768180\n",
            "Iteration 4, loss = 0.35154803\n",
            "Iteration 5, loss = 0.44314355\n",
            "Iteration 6, loss = 0.34371488\n",
            "Iteration 7, loss = 0.32497789\n",
            "Iteration 8, loss = 0.27550777\n",
            "Iteration 9, loss = 0.34747541\n",
            "Iteration 10, loss = 0.30668348\n",
            "Iteration 11, loss = 0.27299512\n",
            "Iteration 12, loss = 0.25471498\n",
            "Iteration 13, loss = 0.28495050\n",
            "Iteration 14, loss = 0.28295117\n",
            "Iteration 15, loss = 0.27163518\n",
            "Iteration 16, loss = 0.20993691\n",
            "Iteration 17, loss = 0.24501759\n",
            "Iteration 18, loss = 0.25449212\n",
            "Iteration 19, loss = 0.22683260\n",
            "Iteration 20, loss = 0.23634060\n",
            "Iteration 21, loss = 0.23899545\n",
            "Iteration 22, loss = 0.32079524\n",
            "Iteration 23, loss = 0.23181144\n",
            "Iteration 24, loss = 0.21044437\n",
            "Iteration 25, loss = 0.32796109\n",
            "Iteration 26, loss = 0.35209567\n",
            "Iteration 27, loss = 0.25141879\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000200\n",
            "Iteration 28, loss = 0.19838139\n",
            "Iteration 29, loss = 0.14450734\n",
            "Iteration 30, loss = 0.13829049\n",
            "Iteration 31, loss = 0.12550190\n",
            "Iteration 32, loss = 0.11440108\n",
            "Iteration 33, loss = 0.10391759\n",
            "Iteration 34, loss = 0.09901261\n",
            "Iteration 35, loss = 0.09940046\n",
            "Iteration 36, loss = 0.09601395\n",
            "Iteration 37, loss = 0.09655434\n",
            "Iteration 38, loss = 0.08688428\n",
            "Iteration 39, loss = 0.08319777\n",
            "Iteration 40, loss = 0.07887397\n",
            "Iteration 41, loss = 0.07955650\n",
            "Iteration 42, loss = 0.08022765\n",
            "Iteration 43, loss = 0.07569418\n",
            "Iteration 44, loss = 0.07703780\n",
            "Iteration 45, loss = 0.07105555\n",
            "Iteration 46, loss = 0.06972006\n",
            "Iteration 47, loss = 0.07220773\n",
            "Iteration 48, loss = 0.06604822\n",
            "Iteration 49, loss = 0.06341714\n",
            "Iteration 50, loss = 0.06525211\n",
            "Iteration 51, loss = 0.06219221\n",
            "Iteration 52, loss = 0.06052216\n",
            "Iteration 53, loss = 0.05843917\n",
            "Iteration 54, loss = 0.05727318\n",
            "Iteration 55, loss = 0.05562757\n",
            "Iteration 56, loss = 0.05565589\n",
            "Iteration 57, loss = 0.05335831\n",
            "Iteration 58, loss = 0.05262932\n",
            "Iteration 59, loss = 0.05307172\n",
            "Iteration 60, loss = 0.05109340\n",
            "Iteration 61, loss = 0.04916625\n",
            "Iteration 62, loss = 0.04840455\n",
            "Iteration 63, loss = 0.04762266\n",
            "Iteration 64, loss = 0.04676408\n",
            "Iteration 65, loss = 0.04632804\n",
            "Iteration 66, loss = 0.04585843\n",
            "Iteration 67, loss = 0.04535252\n",
            "Iteration 68, loss = 0.04540847\n",
            "Iteration 69, loss = 0.04449139\n",
            "Iteration 70, loss = 0.04376390\n",
            "Iteration 71, loss = 0.04402897\n",
            "Iteration 72, loss = 0.04353956\n",
            "Iteration 73, loss = 0.04240826\n",
            "Iteration 74, loss = 0.04160398\n",
            "Iteration 75, loss = 0.04122523\n",
            "Iteration 76, loss = 0.04038427\n",
            "Iteration 77, loss = 0.03978123\n",
            "Iteration 78, loss = 0.03953233\n",
            "Iteration 79, loss = 0.03903835\n",
            "Iteration 80, loss = 0.03852226\n",
            "Iteration 81, loss = 0.04003799\n",
            "Iteration 82, loss = 0.03840386\n",
            "Iteration 83, loss = 0.03740539\n",
            "Iteration 84, loss = 0.03729934\n",
            "Iteration 85, loss = 0.03677818\n",
            "Iteration 86, loss = 0.03626704\n",
            "Iteration 87, loss = 0.03581420\n",
            "Iteration 88, loss = 0.03559985\n",
            "Iteration 89, loss = 0.03505085\n",
            "Iteration 90, loss = 0.03465946\n",
            "Iteration 91, loss = 0.03443455\n",
            "Iteration 92, loss = 0.03376333\n",
            "Iteration 93, loss = 0.03370222\n",
            "Iteration 94, loss = 0.03318829\n",
            "Iteration 95, loss = 0.03302443\n",
            "Iteration 96, loss = 0.03264894\n",
            "Iteration 97, loss = 0.03230227\n",
            "Iteration 98, loss = 0.03194279\n",
            "Iteration 99, loss = 0.03178917\n",
            "Iteration 100, loss = 0.03149461\n",
            "Iteration 101, loss = 0.03115935\n",
            "Iteration 102, loss = 0.03103007\n",
            "Iteration 103, loss = 0.03066957\n",
            "Iteration 104, loss = 0.03049191\n",
            "Iteration 105, loss = 0.03005562\n",
            "Iteration 106, loss = 0.03010465\n",
            "Iteration 107, loss = 0.02976253\n",
            "Iteration 108, loss = 0.02950701\n",
            "Iteration 109, loss = 0.02929122\n",
            "Iteration 110, loss = 0.02907268\n",
            "Iteration 111, loss = 0.02886161\n",
            "Iteration 112, loss = 0.02867182\n",
            "Iteration 113, loss = 0.02848451\n",
            "Iteration 114, loss = 0.02833631\n",
            "Iteration 115, loss = 0.02808460\n",
            "Iteration 116, loss = 0.02789165\n",
            "Iteration 117, loss = 0.02763572\n",
            "Iteration 118, loss = 0.02764616\n",
            "Iteration 119, loss = 0.02736946\n",
            "Iteration 120, loss = 0.02720006\n",
            "Iteration 121, loss = 0.02665331\n",
            "Iteration 122, loss = 0.02639742\n",
            "Iteration 123, loss = 0.02593441\n",
            "Iteration 124, loss = 0.02587717\n",
            "Iteration 125, loss = 0.02538332\n",
            "Iteration 126, loss = 0.02536998\n",
            "Iteration 127, loss = 0.02494230\n",
            "Iteration 128, loss = 0.02469924\n",
            "Iteration 129, loss = 0.02448014\n",
            "Iteration 130, loss = 0.02430650\n",
            "Iteration 131, loss = 0.02450825\n",
            "Iteration 132, loss = 0.02415098\n",
            "Iteration 133, loss = 0.02361790\n",
            "Iteration 134, loss = 0.02331236\n",
            "Iteration 135, loss = 0.02322420\n",
            "Iteration 136, loss = 0.02313967\n",
            "Iteration 137, loss = 0.02293231\n",
            "Iteration 138, loss = 0.02272588\n",
            "Iteration 139, loss = 0.02236680\n",
            "Iteration 140, loss = 0.02228677\n",
            "Iteration 141, loss = 0.02206648\n",
            "Iteration 142, loss = 0.02192454\n",
            "Iteration 143, loss = 0.02190251\n",
            "Iteration 144, loss = 0.02156713\n",
            "Iteration 145, loss = 0.02146914\n",
            "Iteration 146, loss = 0.02139615\n",
            "Iteration 147, loss = 0.02108619\n",
            "Iteration 148, loss = 0.02096634\n",
            "Iteration 149, loss = 0.02090125\n",
            "Iteration 150, loss = 0.02076561\n",
            "Iteration 151, loss = 0.02053658\n",
            "Iteration 152, loss = 0.02034006\n",
            "Iteration 153, loss = 0.02017520\n",
            "Iteration 154, loss = 0.01999165\n",
            "Iteration 155, loss = 0.01988775\n",
            "Iteration 156, loss = 0.01978432\n",
            "Iteration 157, loss = 0.01956856\n",
            "Iteration 158, loss = 0.01947447\n",
            "Iteration 159, loss = 0.01930358\n",
            "Iteration 160, loss = 0.01928499\n",
            "Iteration 161, loss = 0.01911631\n",
            "Iteration 162, loss = 0.01896950\n",
            "Iteration 163, loss = 0.01882396\n",
            "Iteration 164, loss = 0.01860651\n",
            "Iteration 165, loss = 0.01832156\n",
            "Iteration 166, loss = 0.01812920\n",
            "Iteration 167, loss = 0.01800310\n",
            "Iteration 168, loss = 0.01789681\n",
            "Iteration 169, loss = 0.01774609\n",
            "Iteration 170, loss = 0.01765247\n",
            "Iteration 171, loss = 0.01755749\n",
            "Iteration 172, loss = 0.01743319\n",
            "Iteration 173, loss = 0.01732882\n",
            "Iteration 174, loss = 0.01723833\n",
            "Iteration 175, loss = 0.01713944\n",
            "Iteration 176, loss = 0.01700968\n",
            "Iteration 177, loss = 0.01688521\n",
            "Iteration 178, loss = 0.01683108\n",
            "Iteration 179, loss = 0.01666649\n",
            "Iteration 180, loss = 0.01656242\n",
            "Iteration 181, loss = 0.01652389\n",
            "Iteration 182, loss = 0.01653542\n",
            "Iteration 183, loss = 0.01629981\n",
            "Iteration 184, loss = 0.01647082\n",
            "Iteration 185, loss = 0.01615494\n",
            "Iteration 186, loss = 0.01684822\n",
            "Iteration 187, loss = 0.01621480\n",
            "Iteration 188, loss = 0.01599454\n",
            "Iteration 189, loss = 0.01574556\n",
            "Iteration 190, loss = 0.01571228\n",
            "Iteration 191, loss = 0.01545728\n",
            "Iteration 192, loss = 0.01537291\n",
            "Iteration 193, loss = 0.01545458\n",
            "Iteration 194, loss = 0.01513228\n",
            "Iteration 195, loss = 0.01509483\n",
            "Iteration 196, loss = 0.01498327\n",
            "Iteration 197, loss = 0.01493109\n",
            "Iteration 198, loss = 0.01485820\n",
            "Iteration 199, loss = 0.01485719\n",
            "Iteration 200, loss = 0.01467323\n",
            "Hidden layer structure: 50\n",
            "Best loss: 0.017739307958565927\n",
            "Training accuracy: 99.70830018562715\n",
            "Test accuracy: 95.61728395061729\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.69423498\n",
            "Iteration 2, loss = 0.32178892\n",
            "Iteration 3, loss = 0.25780837\n",
            "Iteration 4, loss = 0.23785522\n",
            "Iteration 5, loss = 0.24137891\n",
            "Iteration 6, loss = 0.24588129\n",
            "Iteration 7, loss = 0.20964116\n",
            "Iteration 8, loss = 0.20496833\n",
            "Iteration 9, loss = 0.21909564\n",
            "Iteration 10, loss = 0.18061062\n",
            "Iteration 11, loss = 0.15878091\n",
            "Iteration 12, loss = 0.15153469\n",
            "Iteration 13, loss = 0.16911772\n",
            "Iteration 14, loss = 0.17132198\n",
            "Iteration 15, loss = 0.15169002\n",
            "Iteration 16, loss = 0.18234528\n",
            "Iteration 17, loss = 0.15764957\n",
            "Iteration 18, loss = 0.16037966\n",
            "Iteration 19, loss = 0.15493796\n",
            "Iteration 20, loss = 0.12792788\n",
            "Iteration 21, loss = 0.13843379\n",
            "Iteration 22, loss = 0.18599310\n",
            "Iteration 23, loss = 0.12796743\n",
            "Iteration 24, loss = 0.14641560\n",
            "Iteration 25, loss = 0.12853022\n",
            "Iteration 26, loss = 0.14728307\n",
            "Iteration 27, loss = 0.17626959\n",
            "Iteration 28, loss = 0.15600078\n",
            "Iteration 29, loss = 0.15653917\n",
            "Iteration 30, loss = 0.16928446\n",
            "Iteration 31, loss = 0.18667493\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000200\n",
            "Iteration 32, loss = 0.15237851\n",
            "Iteration 33, loss = 0.10905570\n",
            "Iteration 34, loss = 0.09040384\n",
            "Iteration 35, loss = 0.08271968\n",
            "Iteration 36, loss = 0.06633938\n",
            "Iteration 37, loss = 0.05897955\n",
            "Iteration 38, loss = 0.05381626\n",
            "Iteration 39, loss = 0.05065373\n",
            "Iteration 40, loss = 0.04681340\n",
            "Iteration 41, loss = 0.04428641\n",
            "Iteration 42, loss = 0.04170109\n",
            "Iteration 43, loss = 0.04026291\n",
            "Iteration 44, loss = 0.03817076\n",
            "Iteration 45, loss = 0.03611420\n",
            "Iteration 46, loss = 0.03615169\n",
            "Iteration 47, loss = 0.03419391\n",
            "Iteration 48, loss = 0.03327243\n",
            "Iteration 49, loss = 0.03224104\n",
            "Iteration 50, loss = 0.03157997\n",
            "Iteration 51, loss = 0.03077540\n",
            "Iteration 52, loss = 0.03033072\n",
            "Iteration 53, loss = 0.02963326\n",
            "Iteration 54, loss = 0.02880159\n",
            "Iteration 55, loss = 0.02819495\n",
            "Iteration 56, loss = 0.02774880\n",
            "Iteration 57, loss = 0.02721216\n",
            "Iteration 58, loss = 0.02683985\n",
            "Iteration 59, loss = 0.02612466\n",
            "Iteration 60, loss = 0.02539746\n",
            "Iteration 61, loss = 0.02486468\n",
            "Iteration 62, loss = 0.02442856\n",
            "Iteration 63, loss = 0.02331887\n",
            "Iteration 64, loss = 0.02297117\n",
            "Iteration 65, loss = 0.02255073\n",
            "Iteration 66, loss = 0.02214395\n",
            "Iteration 67, loss = 0.02178648\n",
            "Iteration 68, loss = 0.02150742\n",
            "Iteration 69, loss = 0.02122417\n",
            "Iteration 70, loss = 0.02088585\n",
            "Iteration 71, loss = 0.02059983\n",
            "Iteration 72, loss = 0.02026013\n",
            "Iteration 73, loss = 0.02018453\n",
            "Iteration 74, loss = 0.01988285\n",
            "Iteration 75, loss = 0.01970606\n",
            "Iteration 76, loss = 0.01945436\n",
            "Iteration 77, loss = 0.01884082\n",
            "Iteration 78, loss = 0.01857203\n",
            "Iteration 79, loss = 0.01822434\n",
            "Iteration 80, loss = 0.01795287\n",
            "Iteration 81, loss = 0.01775056\n",
            "Iteration 82, loss = 0.01761556\n",
            "Iteration 83, loss = 0.01736047\n",
            "Iteration 84, loss = 0.01717276\n",
            "Iteration 85, loss = 0.01694870\n",
            "Iteration 86, loss = 0.01680128\n",
            "Iteration 87, loss = 0.01663186\n",
            "Iteration 88, loss = 0.01640147\n",
            "Iteration 89, loss = 0.01636305\n",
            "Iteration 90, loss = 0.01614238\n",
            "Iteration 91, loss = 0.01600192\n",
            "Iteration 92, loss = 0.01585789\n",
            "Iteration 93, loss = 0.01562846\n",
            "Iteration 94, loss = 0.01554430\n",
            "Iteration 95, loss = 0.01537781\n",
            "Iteration 96, loss = 0.01525370\n",
            "Iteration 97, loss = 0.01511038\n",
            "Iteration 98, loss = 0.01493684\n",
            "Iteration 99, loss = 0.01479774\n",
            "Iteration 100, loss = 0.01467551\n",
            "Iteration 101, loss = 0.01449612\n",
            "Iteration 102, loss = 0.01437212\n",
            "Iteration 103, loss = 0.01421973\n",
            "Iteration 104, loss = 0.01411993\n",
            "Iteration 105, loss = 0.01397320\n",
            "Iteration 106, loss = 0.01383177\n",
            "Iteration 107, loss = 0.01369780\n",
            "Iteration 108, loss = 0.01360328\n",
            "Iteration 109, loss = 0.01346837\n",
            "Iteration 110, loss = 0.01334975\n",
            "Iteration 111, loss = 0.01322002\n",
            "Iteration 112, loss = 0.01310433\n",
            "Iteration 113, loss = 0.01302529\n",
            "Iteration 114, loss = 0.01288726\n",
            "Iteration 115, loss = 0.01277966\n",
            "Iteration 116, loss = 0.01269840\n",
            "Iteration 117, loss = 0.01257180\n",
            "Iteration 118, loss = 0.01249476\n",
            "Iteration 119, loss = 0.01238871\n",
            "Iteration 120, loss = 0.01228639\n",
            "Iteration 121, loss = 0.01217573\n",
            "Iteration 122, loss = 0.01208619\n",
            "Iteration 123, loss = 0.01198352\n",
            "Iteration 124, loss = 0.01187497\n",
            "Iteration 125, loss = 0.01179440\n",
            "Iteration 126, loss = 0.01166749\n",
            "Iteration 127, loss = 0.01156699\n",
            "Iteration 128, loss = 0.01150750\n",
            "Iteration 129, loss = 0.01140777\n",
            "Iteration 130, loss = 0.01130785\n",
            "Iteration 131, loss = 0.01123833\n",
            "Iteration 132, loss = 0.01110208\n",
            "Iteration 133, loss = 0.01107049\n",
            "Iteration 134, loss = 0.01096504\n",
            "Iteration 135, loss = 0.01089400\n",
            "Iteration 136, loss = 0.01081230\n",
            "Iteration 137, loss = 0.01072740\n",
            "Iteration 138, loss = 0.01064903\n",
            "Iteration 139, loss = 0.01057685\n",
            "Iteration 140, loss = 0.01048821\n",
            "Iteration 141, loss = 0.01042005\n",
            "Iteration 142, loss = 0.01034155\n",
            "Iteration 143, loss = 0.01025218\n",
            "Iteration 144, loss = 0.01019070\n",
            "Iteration 145, loss = 0.01011764\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000040\n",
            "Iteration 146, loss = 0.00982169\n",
            "Iteration 147, loss = 0.00980773\n",
            "Iteration 148, loss = 0.00978792\n",
            "Iteration 149, loss = 0.00977401\n",
            "Iteration 150, loss = 0.00975763\n",
            "Iteration 151, loss = 0.00974077\n",
            "Iteration 152, loss = 0.00972396\n",
            "Iteration 153, loss = 0.00971207\n",
            "Iteration 154, loss = 0.00969580\n",
            "Iteration 155, loss = 0.00968119\n",
            "Iteration 156, loss = 0.00966325\n",
            "Iteration 157, loss = 0.00964960\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000008\n",
            "Iteration 158, loss = 0.00958851\n",
            "Iteration 159, loss = 0.00958565\n",
            "Iteration 160, loss = 0.00958205\n",
            "Iteration 161, loss = 0.00957894\n",
            "Iteration 162, loss = 0.00957603\n",
            "Iteration 163, loss = 0.00957290\n",
            "Iteration 164, loss = 0.00956968\n",
            "Iteration 165, loss = 0.00956753\n",
            "Iteration 166, loss = 0.00956429\n",
            "Iteration 167, loss = 0.00956097\n",
            "Iteration 168, loss = 0.00955839\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000002\n",
            "Iteration 169, loss = 0.00954625\n",
            "Iteration 170, loss = 0.00954570\n",
            "Iteration 171, loss = 0.00954502\n",
            "Iteration 172, loss = 0.00954442\n",
            "Iteration 173, loss = 0.00954396\n",
            "Iteration 174, loss = 0.00954333\n",
            "Iteration 175, loss = 0.00954267\n",
            "Iteration 176, loss = 0.00954206\n",
            "Iteration 177, loss = 0.00954153\n",
            "Iteration 178, loss = 0.00954085\n",
            "Iteration 179, loss = 0.00954030\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000000\n",
            "Iteration 180, loss = 0.00953790\n",
            "Iteration 181, loss = 0.00953776\n",
            "Iteration 182, loss = 0.00953767\n",
            "Iteration 183, loss = 0.00953755\n",
            "Iteration 184, loss = 0.00953742\n",
            "Iteration 185, loss = 0.00953729\n",
            "Iteration 186, loss = 0.00953718\n",
            "Iteration 187, loss = 0.00953708\n",
            "Iteration 188, loss = 0.00953695\n",
            "Iteration 189, loss = 0.00953684\n",
            "Iteration 190, loss = 0.00953673\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Learning rate too small. Stopping.\n",
            "Iteration 1, loss = 0.80596336\n",
            "Iteration 2, loss = 0.30889346\n",
            "Iteration 3, loss = 0.26118580\n",
            "Iteration 4, loss = 0.23519573\n",
            "Iteration 5, loss = 0.18934734\n",
            "Iteration 6, loss = 0.20872826\n",
            "Iteration 7, loss = 0.17967830\n",
            "Iteration 8, loss = 0.24837937\n",
            "Iteration 9, loss = 0.18614701\n",
            "Iteration 10, loss = 0.13650325\n",
            "Iteration 11, loss = 0.16585416\n",
            "Iteration 12, loss = 0.16785147\n",
            "Iteration 13, loss = 0.16192997\n",
            "Iteration 14, loss = 0.14779918\n",
            "Iteration 15, loss = 0.16278391\n",
            "Iteration 16, loss = 0.15950919\n",
            "Iteration 17, loss = 0.14793510\n",
            "Iteration 18, loss = 0.18724699\n",
            "Iteration 19, loss = 0.16716479\n",
            "Iteration 20, loss = 0.21287659\n",
            "Iteration 21, loss = 0.18187940\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000200\n",
            "Iteration 22, loss = 0.10682702\n",
            "Iteration 23, loss = 0.07619952\n",
            "Iteration 24, loss = 0.06107248\n",
            "Iteration 25, loss = 0.05222827\n",
            "Iteration 26, loss = 0.04318618\n",
            "Iteration 27, loss = 0.04133187\n",
            "Iteration 28, loss = 0.03677423\n",
            "Iteration 29, loss = 0.03496924\n",
            "Iteration 30, loss = 0.03337237\n",
            "Iteration 31, loss = 0.03040860\n",
            "Iteration 32, loss = 0.02935818\n",
            "Iteration 33, loss = 0.02804372\n",
            "Iteration 34, loss = 0.02726848\n",
            "Iteration 35, loss = 0.02620234\n",
            "Iteration 36, loss = 0.02503662\n",
            "Iteration 37, loss = 0.02410303\n",
            "Iteration 38, loss = 0.02347788\n",
            "Iteration 39, loss = 0.02249701\n",
            "Iteration 40, loss = 0.02184660\n",
            "Iteration 41, loss = 0.02097215\n",
            "Iteration 42, loss = 0.02014315\n",
            "Iteration 43, loss = 0.01918585\n",
            "Iteration 44, loss = 0.01885660\n",
            "Iteration 45, loss = 0.01844542\n",
            "Iteration 46, loss = 0.01780321\n",
            "Iteration 47, loss = 0.01703573\n",
            "Iteration 48, loss = 0.01644211\n",
            "Iteration 49, loss = 0.01587641\n",
            "Iteration 50, loss = 0.01573453\n",
            "Iteration 51, loss = 0.01528130\n",
            "Iteration 52, loss = 0.01493248\n",
            "Iteration 53, loss = 0.01463564\n",
            "Iteration 54, loss = 0.01421437\n",
            "Iteration 55, loss = 0.01403001\n",
            "Iteration 56, loss = 0.01386347\n",
            "Iteration 57, loss = 0.01348777\n",
            "Iteration 58, loss = 0.01313731\n",
            "Iteration 59, loss = 0.01279644\n",
            "Iteration 60, loss = 0.01266117\n",
            "Iteration 61, loss = 0.01236985\n",
            "Iteration 62, loss = 0.01212072\n",
            "Iteration 63, loss = 0.01188883\n",
            "Iteration 64, loss = 0.01176526\n",
            "Iteration 65, loss = 0.01150823\n",
            "Iteration 66, loss = 0.01124994\n",
            "Iteration 67, loss = 0.01104711\n",
            "Iteration 68, loss = 0.01089009\n",
            "Iteration 69, loss = 0.01071174\n",
            "Iteration 70, loss = 0.01051096\n",
            "Iteration 71, loss = 0.01033421\n",
            "Iteration 72, loss = 0.01023087\n",
            "Iteration 73, loss = 0.01001708\n",
            "Iteration 74, loss = 0.00988001\n",
            "Iteration 75, loss = 0.00963837\n",
            "Iteration 76, loss = 0.00951655\n",
            "Iteration 77, loss = 0.00941350\n",
            "Iteration 78, loss = 0.00921369\n",
            "Iteration 79, loss = 0.00904544\n",
            "Iteration 80, loss = 0.00885827\n",
            "Iteration 81, loss = 0.00872614\n",
            "Iteration 82, loss = 0.00859764\n",
            "Iteration 83, loss = 0.00847024\n",
            "Iteration 84, loss = 0.00835011\n",
            "Iteration 85, loss = 0.00826724\n",
            "Iteration 86, loss = 0.00813750\n",
            "Iteration 87, loss = 0.00803906\n",
            "Iteration 88, loss = 0.00794122\n",
            "Iteration 89, loss = 0.00786726\n",
            "Iteration 90, loss = 0.00774113\n",
            "Iteration 91, loss = 0.00767624\n",
            "Iteration 92, loss = 0.00758457\n",
            "Iteration 93, loss = 0.00750334\n",
            "Iteration 94, loss = 0.00741708\n",
            "Iteration 95, loss = 0.00733991\n",
            "Iteration 96, loss = 0.00726036\n",
            "Iteration 97, loss = 0.00719540\n",
            "Iteration 98, loss = 0.00712005\n",
            "Iteration 99, loss = 0.00704335\n",
            "Iteration 100, loss = 0.00697898\n",
            "Iteration 101, loss = 0.00690202\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000040\n",
            "Iteration 102, loss = 0.00674340\n",
            "Iteration 103, loss = 0.00673026\n",
            "Iteration 104, loss = 0.00671767\n",
            "Iteration 105, loss = 0.00670359\n",
            "Iteration 106, loss = 0.00668967\n",
            "Iteration 107, loss = 0.00667925\n",
            "Iteration 108, loss = 0.00666715\n",
            "Iteration 109, loss = 0.00665443\n",
            "Iteration 110, loss = 0.00664135\n",
            "Iteration 111, loss = 0.00663002\n",
            "Iteration 112, loss = 0.00661705\n",
            "Iteration 113, loss = 0.00660482\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000008\n",
            "Iteration 114, loss = 0.00657387\n",
            "Iteration 115, loss = 0.00657152\n",
            "Iteration 116, loss = 0.00656874\n",
            "Iteration 117, loss = 0.00656658\n",
            "Iteration 118, loss = 0.00656419\n",
            "Iteration 119, loss = 0.00656186\n",
            "Iteration 120, loss = 0.00655957\n",
            "Iteration 121, loss = 0.00655705\n",
            "Iteration 122, loss = 0.00655488\n",
            "Iteration 123, loss = 0.00655233\n",
            "Iteration 124, loss = 0.00654987\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000002\n",
            "Iteration 125, loss = 0.00654382\n",
            "Iteration 126, loss = 0.00654332\n",
            "Iteration 127, loss = 0.00654282\n",
            "Iteration 128, loss = 0.00654237\n",
            "Iteration 129, loss = 0.00654189\n",
            "Iteration 130, loss = 0.00654141\n",
            "Iteration 131, loss = 0.00654092\n",
            "Iteration 132, loss = 0.00654048\n",
            "Iteration 133, loss = 0.00653998\n",
            "Iteration 134, loss = 0.00653949\n",
            "Iteration 135, loss = 0.00653904\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000000\n",
            "Iteration 136, loss = 0.00653779\n",
            "Iteration 137, loss = 0.00653771\n",
            "Iteration 138, loss = 0.00653760\n",
            "Iteration 139, loss = 0.00653753\n",
            "Iteration 140, loss = 0.00653742\n",
            "Iteration 141, loss = 0.00653733\n",
            "Iteration 142, loss = 0.00653724\n",
            "Iteration 143, loss = 0.00653715\n",
            "Iteration 144, loss = 0.00653705\n",
            "Iteration 145, loss = 0.00653695\n",
            "Iteration 146, loss = 0.00653687\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Learning rate too small. Stopping.\n",
            "Iteration 1, loss = 0.73566844\n",
            "Iteration 2, loss = 0.31197883\n",
            "Iteration 3, loss = 0.25348424\n",
            "Iteration 4, loss = 0.20851300\n",
            "Iteration 5, loss = 0.19280469\n",
            "Iteration 6, loss = 0.20559023\n",
            "Iteration 7, loss = 0.20022460\n",
            "Iteration 8, loss = 0.17227006\n",
            "Iteration 9, loss = 0.19921798\n",
            "Iteration 10, loss = 0.17748192\n",
            "Iteration 11, loss = 0.18387010\n",
            "Iteration 12, loss = 0.14328077\n",
            "Iteration 13, loss = 0.13585439\n",
            "Iteration 14, loss = 0.21392684\n",
            "Iteration 15, loss = 0.20113672\n",
            "Iteration 16, loss = 0.19122869\n",
            "Iteration 17, loss = 0.20479248\n",
            "Iteration 18, loss = 0.16222792\n",
            "Iteration 19, loss = 0.19306410\n",
            "Iteration 20, loss = 0.20633173\n",
            "Iteration 21, loss = 0.16851176\n",
            "Iteration 22, loss = 0.16877263\n",
            "Iteration 23, loss = 0.21225051\n",
            "Iteration 24, loss = 0.14544352\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000200\n",
            "Iteration 25, loss = 0.16207160\n",
            "Iteration 26, loss = 0.11464644\n",
            "Iteration 27, loss = 0.10184441\n",
            "Iteration 28, loss = 0.08605306\n",
            "Iteration 29, loss = 0.07588953\n",
            "Iteration 30, loss = 0.06872184\n",
            "Iteration 31, loss = 0.06336899\n",
            "Iteration 32, loss = 0.05707117\n",
            "Iteration 33, loss = 0.05717989\n",
            "Iteration 34, loss = 0.05357568\n",
            "Iteration 35, loss = 0.04696409\n",
            "Iteration 36, loss = 0.04274204\n",
            "Iteration 37, loss = 0.03968784\n",
            "Iteration 38, loss = 0.03641813\n",
            "Iteration 39, loss = 0.03490779\n",
            "Iteration 40, loss = 0.03330723\n",
            "Iteration 41, loss = 0.03280687\n",
            "Iteration 42, loss = 0.03099142\n",
            "Iteration 43, loss = 0.02997196\n",
            "Iteration 44, loss = 0.02919882\n",
            "Iteration 45, loss = 0.02820587\n",
            "Iteration 46, loss = 0.02733864\n",
            "Iteration 47, loss = 0.02684203\n",
            "Iteration 48, loss = 0.02606868\n",
            "Iteration 49, loss = 0.02519897\n",
            "Iteration 50, loss = 0.02481394\n",
            "Iteration 51, loss = 0.02408261\n",
            "Iteration 52, loss = 0.02348232\n",
            "Iteration 53, loss = 0.02299482\n",
            "Iteration 54, loss = 0.02251256\n",
            "Iteration 55, loss = 0.02222187\n",
            "Iteration 56, loss = 0.02160316\n",
            "Iteration 57, loss = 0.02119355\n",
            "Iteration 58, loss = 0.02075534\n",
            "Iteration 59, loss = 0.02022712\n",
            "Iteration 60, loss = 0.01984965\n",
            "Iteration 61, loss = 0.01938739\n",
            "Iteration 62, loss = 0.01911877\n",
            "Iteration 63, loss = 0.01882094\n",
            "Iteration 64, loss = 0.01841746\n",
            "Iteration 65, loss = 0.01816201\n",
            "Iteration 66, loss = 0.01796384\n",
            "Iteration 67, loss = 0.01760306\n",
            "Iteration 68, loss = 0.01732873\n",
            "Iteration 69, loss = 0.01712026\n",
            "Iteration 70, loss = 0.01682794\n",
            "Iteration 71, loss = 0.01662805\n",
            "Iteration 72, loss = 0.01644357\n",
            "Iteration 73, loss = 0.01621752\n",
            "Iteration 74, loss = 0.01601703\n",
            "Iteration 75, loss = 0.01577648\n",
            "Iteration 76, loss = 0.01560286\n",
            "Iteration 77, loss = 0.01540998\n",
            "Iteration 78, loss = 0.01528141\n",
            "Iteration 79, loss = 0.01508038\n",
            "Iteration 80, loss = 0.01489086\n",
            "Iteration 81, loss = 0.01471312\n",
            "Iteration 82, loss = 0.01452231\n",
            "Iteration 83, loss = 0.01441729\n",
            "Iteration 84, loss = 0.01421551\n",
            "Iteration 85, loss = 0.01408278\n",
            "Iteration 86, loss = 0.01391521\n",
            "Iteration 87, loss = 0.01375081\n",
            "Iteration 88, loss = 0.01357860\n",
            "Iteration 89, loss = 0.01345625\n",
            "Iteration 90, loss = 0.01322689\n",
            "Iteration 91, loss = 0.01302412\n",
            "Iteration 92, loss = 0.01282514\n",
            "Iteration 93, loss = 0.01265792\n",
            "Iteration 94, loss = 0.01249500\n",
            "Iteration 95, loss = 0.01227682\n",
            "Iteration 96, loss = 0.01215402\n",
            "Iteration 97, loss = 0.01202691\n",
            "Iteration 98, loss = 0.01188403\n",
            "Iteration 99, loss = 0.01174201\n",
            "Iteration 100, loss = 0.01161264\n",
            "Iteration 101, loss = 0.01149623\n",
            "Iteration 102, loss = 0.01134329\n",
            "Iteration 103, loss = 0.01122837\n",
            "Iteration 104, loss = 0.01113203\n",
            "Iteration 105, loss = 0.01101963\n",
            "Iteration 106, loss = 0.01090913\n",
            "Iteration 107, loss = 0.01083453\n",
            "Iteration 108, loss = 0.01071683\n",
            "Iteration 109, loss = 0.01063480\n",
            "Iteration 110, loss = 0.01054360\n",
            "Iteration 111, loss = 0.01043595\n",
            "Iteration 112, loss = 0.01035500\n",
            "Iteration 113, loss = 0.01027088\n",
            "Iteration 114, loss = 0.01015393\n",
            "Iteration 115, loss = 0.01007713\n",
            "Iteration 116, loss = 0.00997330\n",
            "Iteration 117, loss = 0.00989737\n",
            "Iteration 118, loss = 0.00981316\n",
            "Iteration 119, loss = 0.00971363\n",
            "Iteration 120, loss = 0.00963100\n",
            "Iteration 121, loss = 0.00955186\n",
            "Iteration 122, loss = 0.00947668\n",
            "Iteration 123, loss = 0.00938553\n",
            "Iteration 124, loss = 0.00931340\n",
            "Iteration 125, loss = 0.00921950\n",
            "Iteration 126, loss = 0.00913942\n",
            "Iteration 127, loss = 0.00906292\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000040\n",
            "Iteration 128, loss = 0.00881427\n",
            "Iteration 129, loss = 0.00879322\n",
            "Iteration 130, loss = 0.00877367\n",
            "Iteration 131, loss = 0.00876204\n",
            "Iteration 132, loss = 0.00874912\n",
            "Iteration 133, loss = 0.00873266\n",
            "Iteration 134, loss = 0.00871699\n",
            "Iteration 135, loss = 0.00870291\n",
            "Iteration 136, loss = 0.00868871\n",
            "Iteration 137, loss = 0.00867709\n",
            "Iteration 138, loss = 0.00866286\n",
            "Iteration 139, loss = 0.00864980\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000008\n",
            "Iteration 140, loss = 0.00859867\n",
            "Iteration 141, loss = 0.00859585\n",
            "Iteration 142, loss = 0.00859225\n",
            "Iteration 143, loss = 0.00859043\n",
            "Iteration 144, loss = 0.00858749\n",
            "Iteration 145, loss = 0.00858523\n",
            "Iteration 146, loss = 0.00858233\n",
            "Iteration 147, loss = 0.00857970\n",
            "Iteration 148, loss = 0.00857679\n",
            "Iteration 149, loss = 0.00857402\n",
            "Iteration 150, loss = 0.00857179\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000002\n",
            "Iteration 151, loss = 0.00856140\n",
            "Iteration 152, loss = 0.00856088\n",
            "Iteration 153, loss = 0.00856020\n",
            "Iteration 154, loss = 0.00855972\n",
            "Iteration 155, loss = 0.00855919\n",
            "Iteration 156, loss = 0.00855871\n",
            "Iteration 157, loss = 0.00855814\n",
            "Iteration 158, loss = 0.00855756\n",
            "Iteration 159, loss = 0.00855694\n",
            "Iteration 160, loss = 0.00855653\n",
            "Iteration 161, loss = 0.00855598\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000000\n",
            "Iteration 162, loss = 0.00855397\n",
            "Iteration 163, loss = 0.00855385\n",
            "Iteration 164, loss = 0.00855374\n",
            "Iteration 165, loss = 0.00855362\n",
            "Iteration 166, loss = 0.00855352\n",
            "Iteration 167, loss = 0.00855342\n",
            "Iteration 168, loss = 0.00855331\n",
            "Iteration 169, loss = 0.00855321\n",
            "Iteration 170, loss = 0.00855309\n",
            "Iteration 171, loss = 0.00855298\n",
            "Iteration 172, loss = 0.00855288\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Learning rate too small. Stopping.\n",
            "Hidden layer structure: 100\n",
            "Best loss: 0.008208825170951296\n",
            "Training accuracy: 99.89392734022805\n",
            "Test accuracy: 97.22222222222223\n",
            "Iteration 1, loss = 0.58848188\n",
            "Iteration 2, loss = 0.20465136\n",
            "Iteration 3, loss = 0.18750617\n",
            "Iteration 4, loss = 0.16607684\n",
            "Iteration 5, loss = 0.13895613\n",
            "Iteration 6, loss = 0.14307004\n",
            "Iteration 7, loss = 0.11274598\n",
            "Iteration 8, loss = 0.12041041\n",
            "Iteration 9, loss = 0.12022082\n",
            "Iteration 10, loss = 0.15139306\n",
            "Iteration 11, loss = 0.11170345\n",
            "Iteration 12, loss = 0.10486163\n",
            "Iteration 13, loss = 0.09716023\n",
            "Iteration 14, loss = 0.08299974\n",
            "Iteration 15, loss = 0.08311881\n",
            "Iteration 16, loss = 0.11577763\n",
            "Iteration 17, loss = 0.11383709\n",
            "Iteration 18, loss = 0.08543342\n",
            "Iteration 19, loss = 0.08537006\n",
            "Iteration 20, loss = 0.12839841\n",
            "Iteration 21, loss = 0.08126425\n",
            "Iteration 22, loss = 0.10741261\n",
            "Iteration 23, loss = 0.10700918\n",
            "Iteration 24, loss = 0.13934341\n",
            "Iteration 25, loss = 0.12578251\n",
            "Iteration 26, loss = 0.10838306\n",
            "Iteration 27, loss = 0.17071839\n",
            "Iteration 28, loss = 0.14861487\n",
            "Iteration 29, loss = 0.14771932\n",
            "Iteration 30, loss = 0.11280553\n",
            "Iteration 31, loss = 0.12316735\n",
            "Iteration 32, loss = 0.13358906\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000200\n",
            "Iteration 33, loss = 0.10882024\n",
            "Iteration 34, loss = 0.05908876\n",
            "Iteration 35, loss = 0.04570223\n",
            "Iteration 36, loss = 0.03959233\n",
            "Iteration 37, loss = 0.03132981\n",
            "Iteration 38, loss = 0.02860528\n",
            "Iteration 39, loss = 0.02555038\n",
            "Iteration 40, loss = 0.02486883\n",
            "Iteration 41, loss = 0.02229312\n",
            "Iteration 42, loss = 0.02114697\n",
            "Iteration 43, loss = 0.01905838\n",
            "Iteration 44, loss = 0.01797117\n",
            "Iteration 45, loss = 0.01716264\n",
            "Iteration 46, loss = 0.01604642\n",
            "Iteration 47, loss = 0.01574340\n",
            "Iteration 48, loss = 0.01468328\n",
            "Iteration 49, loss = 0.01398703\n",
            "Iteration 50, loss = 0.01321469\n",
            "Iteration 51, loss = 0.01291806\n",
            "Iteration 52, loss = 0.01248154\n",
            "Iteration 53, loss = 0.01197522\n",
            "Iteration 54, loss = 0.01161738\n",
            "Iteration 55, loss = 0.01124428\n",
            "Iteration 56, loss = 0.01099266\n",
            "Iteration 57, loss = 0.01063227\n",
            "Iteration 58, loss = 0.01024907\n",
            "Iteration 59, loss = 0.00999846\n",
            "Iteration 60, loss = 0.00981230\n",
            "Iteration 61, loss = 0.00949325\n",
            "Iteration 62, loss = 0.00916345\n",
            "Iteration 63, loss = 0.00894695\n",
            "Iteration 64, loss = 0.00872773\n",
            "Iteration 65, loss = 0.00841426\n",
            "Iteration 66, loss = 0.00823229\n",
            "Iteration 67, loss = 0.00808538\n",
            "Iteration 68, loss = 0.00792525\n",
            "Iteration 69, loss = 0.00775625\n",
            "Iteration 70, loss = 0.00756850\n",
            "Iteration 71, loss = 0.00737922\n",
            "Iteration 72, loss = 0.00729414\n",
            "Iteration 73, loss = 0.00717045\n",
            "Iteration 74, loss = 0.00701690\n",
            "Iteration 75, loss = 0.00689456\n",
            "Iteration 76, loss = 0.00674450\n",
            "Iteration 77, loss = 0.00662648\n",
            "Iteration 78, loss = 0.00645898\n",
            "Iteration 79, loss = 0.00640195\n",
            "Iteration 80, loss = 0.00623716\n",
            "Iteration 81, loss = 0.00609478\n",
            "Iteration 82, loss = 0.00600575\n",
            "Iteration 83, loss = 0.00578286\n",
            "Iteration 84, loss = 0.00572470\n",
            "Iteration 85, loss = 0.00558700\n",
            "Iteration 86, loss = 0.00544771\n",
            "Iteration 87, loss = 0.00531413\n",
            "Iteration 88, loss = 0.00526100\n",
            "Iteration 89, loss = 0.00517712\n",
            "Iteration 90, loss = 0.00507287\n",
            "Iteration 91, loss = 0.00499777\n",
            "Iteration 92, loss = 0.00493491\n",
            "Iteration 93, loss = 0.00487128\n",
            "Iteration 94, loss = 0.00480088\n",
            "Iteration 95, loss = 0.00472341\n",
            "Iteration 96, loss = 0.00466298\n",
            "Iteration 97, loss = 0.00460656\n",
            "Iteration 98, loss = 0.00454597\n",
            "Iteration 99, loss = 0.00450825\n",
            "Iteration 100, loss = 0.00444583\n",
            "Iteration 101, loss = 0.00438945\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000040\n",
            "Iteration 102, loss = 0.00425318\n",
            "Iteration 103, loss = 0.00424191\n",
            "Iteration 104, loss = 0.00422956\n",
            "Iteration 105, loss = 0.00422082\n",
            "Iteration 106, loss = 0.00420994\n",
            "Iteration 107, loss = 0.00420066\n",
            "Iteration 108, loss = 0.00419253\n",
            "Iteration 109, loss = 0.00418198\n",
            "Iteration 110, loss = 0.00417323\n",
            "Iteration 111, loss = 0.00416440\n",
            "Iteration 112, loss = 0.00415540\n",
            "Iteration 113, loss = 0.00414723\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000008\n",
            "Iteration 114, loss = 0.00412010\n",
            "Iteration 115, loss = 0.00411827\n",
            "Iteration 116, loss = 0.00411641\n",
            "Iteration 117, loss = 0.00411489\n",
            "Iteration 118, loss = 0.00411293\n",
            "Iteration 119, loss = 0.00411124\n",
            "Iteration 120, loss = 0.00410952\n",
            "Iteration 121, loss = 0.00410768\n",
            "Iteration 122, loss = 0.00410596\n",
            "Iteration 123, loss = 0.00410425\n",
            "Iteration 124, loss = 0.00410243\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000002\n",
            "Iteration 125, loss = 0.00409729\n",
            "Iteration 126, loss = 0.00409698\n",
            "Iteration 127, loss = 0.00409660\n",
            "Iteration 128, loss = 0.00409625\n",
            "Iteration 129, loss = 0.00409593\n",
            "Iteration 130, loss = 0.00409558\n",
            "Iteration 131, loss = 0.00409524\n",
            "Iteration 132, loss = 0.00409486\n",
            "Iteration 133, loss = 0.00409463\n",
            "Iteration 134, loss = 0.00409413\n",
            "Iteration 135, loss = 0.00409385\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000000\n",
            "Iteration 136, loss = 0.00409284\n",
            "Iteration 137, loss = 0.00409274\n",
            "Iteration 138, loss = 0.00409267\n",
            "Iteration 139, loss = 0.00409261\n",
            "Iteration 140, loss = 0.00409254\n",
            "Iteration 141, loss = 0.00409247\n",
            "Iteration 142, loss = 0.00409239\n",
            "Iteration 143, loss = 0.00409234\n",
            "Iteration 144, loss = 0.00409226\n",
            "Iteration 145, loss = 0.00409219\n",
            "Iteration 146, loss = 0.00409212\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Learning rate too small. Stopping.\n",
            "Iteration 1, loss = 0.65129959\n",
            "Iteration 2, loss = 0.28636489\n",
            "Iteration 3, loss = 0.18981492\n",
            "Iteration 4, loss = 0.17174882\n",
            "Iteration 5, loss = 0.17933669\n",
            "Iteration 6, loss = 0.18239975\n",
            "Iteration 7, loss = 0.13999094\n",
            "Iteration 8, loss = 0.13551704\n",
            "Iteration 9, loss = 0.17437205\n",
            "Iteration 10, loss = 0.13000214\n",
            "Iteration 11, loss = 0.08457595\n",
            "Iteration 12, loss = 0.07603518\n",
            "Iteration 13, loss = 0.08226666\n",
            "Iteration 14, loss = 0.08876652\n",
            "Iteration 15, loss = 0.10238973\n",
            "Iteration 16, loss = 0.09541713\n",
            "Iteration 17, loss = 0.08957054\n",
            "Iteration 18, loss = 0.10522793\n",
            "Iteration 19, loss = 0.12212725\n",
            "Iteration 20, loss = 0.11720247\n",
            "Iteration 21, loss = 0.07103139\n",
            "Iteration 22, loss = 0.09073255\n",
            "Iteration 23, loss = 0.08116773\n",
            "Iteration 24, loss = 0.08183533\n",
            "Iteration 25, loss = 0.13406135\n",
            "Iteration 26, loss = 0.11809197\n",
            "Iteration 27, loss = 0.10986518\n",
            "Iteration 28, loss = 0.09429187\n",
            "Iteration 29, loss = 0.08338657\n",
            "Iteration 30, loss = 0.13282010\n",
            "Iteration 31, loss = 0.13257221\n",
            "Iteration 32, loss = 0.08647718\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000200\n",
            "Iteration 33, loss = 0.06455211\n",
            "Iteration 34, loss = 0.03762182\n",
            "Iteration 35, loss = 0.03068207\n",
            "Iteration 36, loss = 0.02530805\n",
            "Iteration 37, loss = 0.02289800\n",
            "Iteration 38, loss = 0.02050196\n",
            "Iteration 39, loss = 0.01925805\n",
            "Iteration 40, loss = 0.01805302\n",
            "Iteration 41, loss = 0.01739033\n",
            "Iteration 42, loss = 0.01642544\n",
            "Iteration 43, loss = 0.01585174\n",
            "Iteration 44, loss = 0.01498699\n",
            "Iteration 45, loss = 0.01437708\n",
            "Iteration 46, loss = 0.01382104\n",
            "Iteration 47, loss = 0.01316744\n",
            "Iteration 48, loss = 0.01275507\n",
            "Iteration 49, loss = 0.01202416\n",
            "Iteration 50, loss = 0.01139253\n",
            "Iteration 51, loss = 0.01092532\n",
            "Iteration 52, loss = 0.01079167\n",
            "Iteration 53, loss = 0.01033075\n",
            "Iteration 54, loss = 0.00993997\n",
            "Iteration 55, loss = 0.00964059\n",
            "Iteration 56, loss = 0.00932883\n",
            "Iteration 57, loss = 0.00900803\n",
            "Iteration 58, loss = 0.00867697\n",
            "Iteration 59, loss = 0.00838403\n",
            "Iteration 60, loss = 0.00813030\n",
            "Iteration 61, loss = 0.00789336\n",
            "Iteration 62, loss = 0.00767129\n",
            "Iteration 63, loss = 0.00746913\n",
            "Iteration 64, loss = 0.00726123\n",
            "Iteration 65, loss = 0.00706936\n",
            "Iteration 66, loss = 0.00690632\n",
            "Iteration 67, loss = 0.00672943\n",
            "Iteration 68, loss = 0.00657278\n",
            "Iteration 69, loss = 0.00648197\n",
            "Iteration 70, loss = 0.00630736\n",
            "Iteration 71, loss = 0.00617892\n",
            "Iteration 72, loss = 0.00605743\n",
            "Iteration 73, loss = 0.00594740\n",
            "Iteration 74, loss = 0.00583802\n",
            "Iteration 75, loss = 0.00575201\n",
            "Iteration 76, loss = 0.00561744\n",
            "Iteration 77, loss = 0.00552682\n",
            "Iteration 78, loss = 0.00544977\n",
            "Iteration 79, loss = 0.00534335\n",
            "Iteration 80, loss = 0.00526372\n",
            "Iteration 81, loss = 0.00515882\n",
            "Iteration 82, loss = 0.00510311\n",
            "Iteration 83, loss = 0.00502184\n",
            "Iteration 84, loss = 0.00494882\n",
            "Iteration 85, loss = 0.00484585\n",
            "Iteration 86, loss = 0.00478631\n",
            "Iteration 87, loss = 0.00473555\n",
            "Iteration 88, loss = 0.00465316\n",
            "Iteration 89, loss = 0.00459511\n",
            "Iteration 90, loss = 0.00449984\n",
            "Iteration 91, loss = 0.00445423\n",
            "Iteration 92, loss = 0.00439989\n",
            "Iteration 93, loss = 0.00434367\n",
            "Iteration 94, loss = 0.00426882\n",
            "Iteration 95, loss = 0.00422958\n",
            "Iteration 96, loss = 0.00417118\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000040\n",
            "Iteration 97, loss = 0.00406037\n",
            "Iteration 98, loss = 0.00404863\n",
            "Iteration 99, loss = 0.00403963\n",
            "Iteration 100, loss = 0.00402824\n",
            "Iteration 101, loss = 0.00401905\n",
            "Iteration 102, loss = 0.00400938\n",
            "Iteration 103, loss = 0.00399940\n",
            "Iteration 104, loss = 0.00398962\n",
            "Iteration 105, loss = 0.00398043\n",
            "Iteration 106, loss = 0.00397051\n",
            "Iteration 107, loss = 0.00396053\n",
            "Iteration 108, loss = 0.00395114\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000008\n",
            "Iteration 109, loss = 0.00392903\n",
            "Iteration 110, loss = 0.00392707\n",
            "Iteration 111, loss = 0.00392518\n",
            "Iteration 112, loss = 0.00392349\n",
            "Iteration 113, loss = 0.00392141\n",
            "Iteration 114, loss = 0.00391963\n",
            "Iteration 115, loss = 0.00391747\n",
            "Iteration 116, loss = 0.00391587\n",
            "Iteration 117, loss = 0.00391395\n",
            "Iteration 118, loss = 0.00391214\n",
            "Iteration 119, loss = 0.00391015\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000002\n",
            "Iteration 120, loss = 0.00390580\n",
            "Iteration 121, loss = 0.00390546\n",
            "Iteration 122, loss = 0.00390505\n",
            "Iteration 123, loss = 0.00390469\n",
            "Iteration 124, loss = 0.00390432\n",
            "Iteration 125, loss = 0.00390391\n",
            "Iteration 126, loss = 0.00390355\n",
            "Iteration 127, loss = 0.00390316\n",
            "Iteration 128, loss = 0.00390276\n",
            "Iteration 129, loss = 0.00390241\n",
            "Iteration 130, loss = 0.00390202\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000000\n",
            "Iteration 131, loss = 0.00390118\n",
            "Iteration 132, loss = 0.00390111\n",
            "Iteration 133, loss = 0.00390104\n",
            "Iteration 134, loss = 0.00390095\n",
            "Iteration 135, loss = 0.00390088\n",
            "Iteration 136, loss = 0.00390080\n",
            "Iteration 137, loss = 0.00390073\n",
            "Iteration 138, loss = 0.00390066\n",
            "Iteration 139, loss = 0.00390058\n",
            "Iteration 140, loss = 0.00390050\n",
            "Iteration 141, loss = 0.00390043\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Learning rate too small. Stopping.\n",
            "Iteration 1, loss = 0.57728039\n",
            "Iteration 2, loss = 0.25365682\n",
            "Iteration 3, loss = 0.18914841\n",
            "Iteration 4, loss = 0.14553329\n",
            "Iteration 5, loss = 0.13384257\n",
            "Iteration 6, loss = 0.11712149\n",
            "Iteration 7, loss = 0.11074173\n",
            "Iteration 8, loss = 0.14597314\n",
            "Iteration 9, loss = 0.09743489\n",
            "Iteration 10, loss = 0.10734627\n",
            "Iteration 11, loss = 0.06660130\n",
            "Iteration 12, loss = 0.07667255\n",
            "Iteration 13, loss = 0.07957380\n",
            "Iteration 14, loss = 0.07967825\n",
            "Iteration 15, loss = 0.07937700\n",
            "Iteration 16, loss = 0.06299405\n",
            "Iteration 17, loss = 0.06764535\n",
            "Iteration 18, loss = 0.05627130\n",
            "Iteration 19, loss = 0.09614168\n",
            "Iteration 20, loss = 0.08797057\n",
            "Iteration 21, loss = 0.08909420\n",
            "Iteration 22, loss = 0.06554139\n",
            "Iteration 23, loss = 0.11766185\n",
            "Iteration 24, loss = 0.05453095\n",
            "Iteration 25, loss = 0.05759762\n",
            "Iteration 26, loss = 0.07780803\n",
            "Iteration 27, loss = 0.08631981\n",
            "Iteration 28, loss = 0.07832287\n",
            "Iteration 29, loss = 0.09175914\n",
            "Iteration 30, loss = 0.12497468\n",
            "Iteration 31, loss = 0.09870511\n",
            "Iteration 32, loss = 0.08290968\n",
            "Iteration 33, loss = 0.09174044\n",
            "Iteration 34, loss = 0.13746132\n",
            "Iteration 35, loss = 0.10345617\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000200\n",
            "Iteration 36, loss = 0.06621365\n",
            "Iteration 37, loss = 0.04210178\n",
            "Iteration 38, loss = 0.03169697\n",
            "Iteration 39, loss = 0.02657640\n",
            "Iteration 40, loss = 0.02297399\n",
            "Iteration 41, loss = 0.02009197\n",
            "Iteration 42, loss = 0.01797535\n",
            "Iteration 43, loss = 0.01570325\n",
            "Iteration 44, loss = 0.01455090\n",
            "Iteration 45, loss = 0.01327320\n",
            "Iteration 46, loss = 0.01286503\n",
            "Iteration 47, loss = 0.01154120\n",
            "Iteration 48, loss = 0.01088033\n",
            "Iteration 49, loss = 0.01027814\n",
            "Iteration 50, loss = 0.00991602\n",
            "Iteration 51, loss = 0.00939788\n",
            "Iteration 52, loss = 0.00906104\n",
            "Iteration 53, loss = 0.00873324\n",
            "Iteration 54, loss = 0.00845348\n",
            "Iteration 55, loss = 0.00817322\n",
            "Iteration 56, loss = 0.00790197\n",
            "Iteration 57, loss = 0.00770231\n",
            "Iteration 58, loss = 0.00740057\n",
            "Iteration 59, loss = 0.00716974\n",
            "Iteration 60, loss = 0.00699541\n",
            "Iteration 61, loss = 0.00679570\n",
            "Iteration 62, loss = 0.00664334\n",
            "Iteration 63, loss = 0.00646266\n",
            "Iteration 64, loss = 0.00632199\n",
            "Iteration 65, loss = 0.00618480\n",
            "Iteration 66, loss = 0.00602121\n",
            "Iteration 67, loss = 0.00589684\n",
            "Iteration 68, loss = 0.00574784\n",
            "Iteration 69, loss = 0.00565638\n",
            "Iteration 70, loss = 0.00553839\n",
            "Iteration 71, loss = 0.00543410\n",
            "Iteration 72, loss = 0.00532430\n",
            "Iteration 73, loss = 0.00523599\n",
            "Iteration 74, loss = 0.00513599\n",
            "Iteration 75, loss = 0.00504063\n",
            "Iteration 76, loss = 0.00494899\n",
            "Iteration 77, loss = 0.00485785\n",
            "Iteration 78, loss = 0.00477862\n",
            "Iteration 79, loss = 0.00468602\n",
            "Iteration 80, loss = 0.00461196\n",
            "Iteration 81, loss = 0.00455278\n",
            "Iteration 82, loss = 0.00446647\n",
            "Iteration 83, loss = 0.00435475\n",
            "Iteration 84, loss = 0.00415694\n",
            "Iteration 85, loss = 0.00404778\n",
            "Iteration 86, loss = 0.00392610\n",
            "Iteration 87, loss = 0.00386457\n",
            "Iteration 88, loss = 0.00379674\n",
            "Iteration 89, loss = 0.00372324\n",
            "Iteration 90, loss = 0.00366504\n",
            "Iteration 91, loss = 0.00361377\n",
            "Iteration 92, loss = 0.00355446\n",
            "Iteration 93, loss = 0.00350928\n",
            "Iteration 94, loss = 0.00346547\n",
            "Iteration 95, loss = 0.00342348\n",
            "Iteration 96, loss = 0.00337807\n",
            "Iteration 97, loss = 0.00333760\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000040\n",
            "Iteration 98, loss = 0.00324942\n",
            "Iteration 99, loss = 0.00324085\n",
            "Iteration 100, loss = 0.00323293\n",
            "Iteration 101, loss = 0.00322609\n",
            "Iteration 102, loss = 0.00321845\n",
            "Iteration 103, loss = 0.00321107\n",
            "Iteration 104, loss = 0.00320381\n",
            "Iteration 105, loss = 0.00319633\n",
            "Iteration 106, loss = 0.00318981\n",
            "Iteration 107, loss = 0.00318224\n",
            "Iteration 108, loss = 0.00317404\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000008\n",
            "Iteration 109, loss = 0.00315780\n",
            "Iteration 110, loss = 0.00315657\n",
            "Iteration 111, loss = 0.00315496\n",
            "Iteration 112, loss = 0.00315342\n",
            "Iteration 113, loss = 0.00315206\n",
            "Iteration 114, loss = 0.00315068\n",
            "Iteration 115, loss = 0.00314916\n",
            "Iteration 116, loss = 0.00314774\n",
            "Iteration 117, loss = 0.00314609\n",
            "Iteration 118, loss = 0.00314487\n",
            "Iteration 119, loss = 0.00314346\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000002\n",
            "Iteration 120, loss = 0.00314005\n",
            "Iteration 121, loss = 0.00313978\n",
            "Iteration 122, loss = 0.00313950\n",
            "Iteration 123, loss = 0.00313918\n",
            "Iteration 124, loss = 0.00313890\n",
            "Iteration 125, loss = 0.00313863\n",
            "Iteration 126, loss = 0.00313834\n",
            "Iteration 127, loss = 0.00313804\n",
            "Iteration 128, loss = 0.00313776\n",
            "Iteration 129, loss = 0.00313750\n",
            "Iteration 130, loss = 0.00313720\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000000\n",
            "Iteration 131, loss = 0.00313654\n",
            "Iteration 132, loss = 0.00313647\n",
            "Iteration 133, loss = 0.00313642\n",
            "Iteration 134, loss = 0.00313636\n",
            "Iteration 135, loss = 0.00313631\n",
            "Iteration 136, loss = 0.00313625\n",
            "Iteration 137, loss = 0.00313619\n",
            "Iteration 138, loss = 0.00313613\n",
            "Iteration 139, loss = 0.00313607\n",
            "Iteration 140, loss = 0.00313602\n",
            "Iteration 141, loss = 0.00313596\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Learning rate too small. Stopping.\n",
            "Hidden layer structure: 200\n",
            "Best loss: 0.003709502788996422\n",
            "Training accuracy: 100.0\n",
            "Test accuracy: 97.71604938271604\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Initialize the neural network\n",
        "clf = MLPClassifier(\n",
        "    activation='tanh',\n",
        "    solver='sgd',\n",
        "    batch_size=1,\n",
        "    alpha=0,\n",
        "    learning_rate='adaptive',\n",
        "    verbose=1)\n",
        "\n",
        "# Define a list of hidden layer sizes to test\n",
        "hidden_layer_sizes = [5, 10, 20, 50, 100, 200]\n",
        "\n",
        "# Initialize arrays to store the scores\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "best_loss = []\n",
        "\n",
        "# Loop over the different hidden layer sizes\n",
        "for C in hidden_layer_sizes:\n",
        "    \n",
        "    train_scores_iter, test_scores_iter, best_loss_iter = [], [], []\n",
        "\n",
        "    for i in range(3):\n",
        "        # Set the hidden layer size\n",
        "        clf.set_params(hidden_layer_sizes=C)\n",
        "\n",
        "        # Train the network\n",
        "        clf.fit(X_train, y_train)\n",
        "        \n",
        "        # Measure the score on the training set\n",
        "        train_scores_iter.append(clf.score(X_train, y_train))\n",
        "        \n",
        "        # Measure the score on the test set\n",
        "        test_scores_iter.append(clf.score(X_test, y_test))\n",
        "\n",
        "        # Get the best loss\n",
        "        best_loss_iter.append(clf.best_loss_)\n",
        "    \n",
        "    # Compute the mean of the scores over the 3 iterations\n",
        "    train_scores_mean = np.mean(train_scores_iter)\n",
        "    test_scores_mean = np.mean(test_scores_iter)\n",
        "    best_loss_mean = np.mean(best_loss_iter)\n",
        "\n",
        "    # Store the mean scores in the arrays\n",
        "    train_scores.append(train_scores_mean)\n",
        "    test_scores.append(test_scores_mean)\n",
        "    best_loss.append(best_loss_mean)\n",
        "    \n",
        "    # Print the results\n",
        "    print(f\"Hidden layer structure: {C}\")\n",
        "    print(f\"Best loss: {best_loss_mean}\")\n",
        "    print(f\"Training accuracy: {train_scores_mean*100}\")\n",
        "    print(f\"Test accuracy: {test_scores_mean*100}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "2P1p4Iao3G6p",
        "outputId": "73c7f406-030c-4ade-87fd-e4b9ec8073da"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the figure\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Plot the training and test scores\n",
        "ax.plot(hidden_layer_sizes, train_scores, 'o-', color='black', label='Training')\n",
        "ax.plot(hidden_layer_sizes, test_scores, 'o-', color='grey', label='Generalization')\n",
        "ax.plot(hidden_layer_sizes, best_loss, 'o-', color='tab:red', label='Best Loss')\n",
        "\n",
        "# Set the axis labels and title\n",
        "ax.set_xlabel('Number of neurons in hidden layer')\n",
        "ax.set_ylabel('Recognition rate')\n",
        "ax.set_title('Neural Network Performance')\n",
        "\n",
        "# Add a legend to the plot\n",
        "ax.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DCwRcQ1CzsFM"
      },
      "source": [
        "# 3 Cross-validation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EnFvHkTczw3M"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import validation_curve\n",
        "\n",
        "# Define neural network parameters\n",
        "C = range(1, 50)\n",
        "\n",
        "# Train neural network with early stopping and cross-validation\n",
        "nn = MLPClassifier(\n",
        "    activation='tanh',\n",
        "    solver='adam',\n",
        "    batch_size=1,\n",
        "    alpha=0,\n",
        "    learning_rate='adaptive',\n",
        "    early_stopping=True,\n",
        "    validation_fraction=0.2\n",
        ")\n",
        "\n",
        "train_scores, validation_scores = validation_curve(\n",
        "    nn, X_train, y_train,\n",
        "    param_name=\"hidden_layer_sizes\",\n",
        "    param_range=C,\n",
        "    scoring=\"accuracy\",\n",
        "    n_jobs=2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "9wTd8jiz6IwF",
        "outputId": "071a579f-3da0-453b-99da-2326511fb996"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Calculate mean and standard deviation of training and validation scores\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "validation_mean = np.mean(validation_scores, axis=1)\n",
        "validation_std = np.std(validation_scores, axis=1)\n",
        "\n",
        "# Plot validation and training scores with shaded standard deviation\n",
        "plt.plot(C, validation_mean, label=\"Validation Score\", color=\"tab:blue\")\n",
        "plt.plot(C, train_mean, label=\"Training Score\", color=\"tab:red\")\n",
        "plt.fill_between(C, validation_mean - validation_std, validation_mean + validation_std, alpha=0.2, color=\"r\")\n",
        "plt.fill_between(C, train_mean - train_std, train_mean + train_std, alpha=0.2, color=\"b\")\n",
        "\n",
        "# Add legend and labels\n",
        "plt.legend(loc=\"best\")\n",
        "plt.title(\"Recognition Rate vs. Number of Hidden Neurons\")\n",
        "plt.xlabel('Number of Hidden Neurons')\n",
        "plt.ylabel('Recognition Rate')\n",
        "plt.ylim(0.0, 1.0)\n",
        "plt.xlim(1, 50)\n",
        "\n",
        "# Print the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "GRld0jEZ7PvW",
        "outputId": "29c46156-a8e2-487e-f569-cd18070dfc0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimal number of hidden neurons: 34\n",
            "Training score: 0.9968178202068417\n",
            "Generalization score: 0.9592592592592593\n",
            "Recognition rate: 95.92592592592592\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Select the optimal number of hidden neurons\n",
        "best_C = C[np.argmax(validation_mean)]\n",
        "\n",
        "# Train the neural network\n",
        "clf = MLPClassifier(hidden_layer_sizes=best_C, activation='tanh', solver='adam', batch_size=1, alpha=0, learning_rate='adaptive', early_stopping=True, validation_fraction=0.2).fit(X_train, y_train)\n",
        "\n",
        "# Calculate scores\n",
        "train_score, test_score = clf.score(X_train, y_train), clf.score(X_test, y_test)\n",
        "\n",
        "# Print scores\n",
        "print(\"Optimal number of hidden neurons: \" + str(best_C))\n",
        "print(\"Training score: \" + str(train_score))\n",
        "print(\"Generalization score: \" + str(test_score))\n",
        "\n",
        "# Predict labels for test set, calculate confusion matrix and print it\n",
        "y_pred = clf.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(y_test)).plot(cmap='OrRd')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "\n",
        "# Calculate and print recognition rate for test set\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Recognition rate: \" + str(accuracy*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "pKaVfsD5-s_H"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import time\n",
        "\n",
        "# Data splitting into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=1)\n",
        "\n",
        "# Setting the parameter grid to test\n",
        "param_grid = {'n_neighbors': range(1, 16)}\n",
        "\n",
        "# Initializing an array to store classification times\n",
        "times = []\n",
        "\n",
        "# Creating the k-nearest neighbors classifier\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Creating the GridSearchCV object to search for the best hyperparameters\n",
        "grid_search = GridSearchCV(knn, param_grid, cv=5)\n",
        "\n",
        "# Training the GridSearchCV object on the training set and retrieving the model with the best hyperparameters\n",
        "best_knn = grid_search.fit(X_train, y_train).best_estimator_\n",
        "\n",
        "# Calculating the scores for each k\n",
        "scores, times = [], []\n",
        "for k in range(1, 16):\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    # Measuring the classification time\n",
        "    t0 = time.time()\n",
        "    score = cross_val_score(knn, X_train, y_train, cv=5).mean()\n",
        "    t1 = time.time()\n",
        "    times.append(t1 - t0)\n",
        "    scores.append(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "O8ZuIzwp_U3u",
        "outputId": "60fd4491-b579-4657-db7b-1ca219c1cd76"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Print the recognition rate and classification time for each k\n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel('Number of neighbors considered')\n",
        "ax1.set_ylabel('Recognition rate', color=\"red\")\n",
        "ax1.plot(range(1, 16), scores, '-o', color=\"red\")\n",
        "ax1.tick_params(axis='y', labelcolor=\"red\")\n",
        "ax1.set_ylim([0.85, 1])\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.set_ylabel('Classification time (s)', color=\"blue\") # x-label is already managed by ax1\n",
        "ax2.plot(range(1, 16), times, '-o', color=\"blue\")\n",
        "ax2.tick_params(axis='y', labelcolor=\"blue\")\n",
        "ax2.set_ylim([0, max(times)*1.1])\n",
        "\n",
        "plt.title('Scores and classification time of the KNN method function of k')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cSZ5S8pNC07m"
      },
      "source": [
        "# 4 Rejet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "UojHu_iDDUuJ"
      },
      "outputs": [],
      "source": [
        "def argmax_reject_threshold(y, threshold):\n",
        "    y_argmax = np.argmax(y, axis=1)\n",
        "    y_masked = np.ma.array(y_argmax, mask=(np.amax(y, axis=1) < threshold))\n",
        "    return y_masked.filled(-1)\n",
        "\n",
        "def argmax_top2_reject_threshold(y, threshold):\n",
        "    y_argmax = np.argmax(y, axis=1)\n",
        "    y_top2 = np.sort(y, axis=1)[:,-1:-3:-1]\n",
        "    y_masked = np.ma.array(y_argmax, mask=((y_top2[:,0] - y_top2[:,1]) < threshold))\n",
        "    return y_masked.filled(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "nB17fHMhDWZ7"
      },
      "outputs": [],
      "source": [
        "# Initialize empty lists for rejection rate, accuracy rate, and rejected data points\n",
        "rejection_rate = []\n",
        "accuracy_rate = []\n",
        "rejection_rate_top2 = []\n",
        "accuracy_rate_top2 = []\n",
        "rejected_x = []\n",
        "rejected_y = []\n",
        "\n",
        "# Get predicted probabilities for test set using classifier object clf\n",
        "predict_clf = clf.predict_proba(X_test)\n",
        "\n",
        "# Loop through different threshold values\n",
        "for threshold in np.arange(0, 1.01, 0.01):\n",
        "  # Get predictions for test set using reject threshold and top-2 reject threshold\n",
        "  predictions_reject = argmax_reject_threshold(predict_clf, threshold)\n",
        "  predictions_reject_top2 = argmax_top2_reject_threshold(predict_clf, threshold)\n",
        "\n",
        "  # Initialize variables for counting correct, incorrect, and rejected predictions\n",
        "  correct = 0\n",
        "  incorrect = 0\n",
        "  rejected = 0\n",
        "  correct_top2 = 0\n",
        "  incorrect_top2 = 0\n",
        "  rejected_top2 = 0\n",
        "\n",
        "  # Loop through predictions and count correct, incorrect, and rejected predictions\n",
        "  for i in range(len(predictions_reject)):\n",
        "      if predictions_reject[i] == y_test[i]:\n",
        "          correct += 1\n",
        "      elif predictions_reject[i] == -1:\n",
        "          rejected += 1\n",
        "          rejected_x.append(X_test[i])\n",
        "          rejected_y.append(y_test[i])\n",
        "      else:\n",
        "          incorrect += 1\n",
        "          \n",
        "      if predictions_reject_top2[i] == y_test[i]:\n",
        "          correct_top2 += 1\n",
        "      elif predictions_reject_top2[i] == -1:\n",
        "          rejected_top2 += 1\n",
        "      else:\n",
        "          incorrect_top2 += 1\n",
        "\n",
        "  # Calculate and store rejection rate and accuracy rate for current threshold\n",
        "  rejection_rate.append(rejected/len(predictions_reject))\n",
        "  accuracy_rate.append(correct/len(predictions_reject))\n",
        "  rejection_rate_top2.append(rejected_top2/len(predictions_reject_top2))\n",
        "  accuracy_rate_top2.append(correct_top2/len(predictions_reject_top2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "wl90krnkFmlt",
        "outputId": "f4fd5682-7487-4b24-b81d-fbf8159fe9e5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(rejection_rate, color=\"tab:red\", label=\"Distance rejection\")\n",
        "plt.plot(accuracy_rate, color=\"tab:green\", label=\"Correctly classified\")\n",
        "plt.grid()\n",
        "plt.xlabel('Threshold')\n",
        "plt.ylabel('Rejection rate')\n",
        "plt.legend()\n",
        "plt.title('Distance rejection')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "5m3ZqCu0Fnsj",
        "outputId": "014809d1-9219-4d33-df5c-32b541dd6fe8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(rejection_rate_top2, color=\"tab:red\", label=\"Ambiguity rejection\")\n",
        "plt.plot(accuracy_rate_top2, color=\"tab:green\", label=\"Correctly classified\")\n",
        "plt.grid()\n",
        "plt.xlabel('Threshold')\n",
        "plt.ylabel('Rejection rate')\n",
        "plt.legend()\n",
        "plt.title('Ambiguity rejection')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FWi42c5_FrEB"
      },
      "source": [
        "# 5 Cascade de classifieurs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "iGLzeNeCF7J_"
      },
      "outputs": [],
      "source": [
        "# Use the distance rejection method to predict labels for test data\n",
        "predictions_reject = argmax_reject_threshold(predict_clf, 0.43)\n",
        "\n",
        "# Train a KNN classifier with one neighbor\n",
        "one_NN = KNeighborsClassifier(n_neighbors=1)\n",
        "one_NN.fit(X_train, y_train)\n",
        "\n",
        "# Predict labels for test data using KNN\n",
        "predict_knn = one_NN.predict(X_test)\n",
        "\n",
        "# Initialize counters and result array\n",
        "correct_distance = 0 # count the number of examples correctly predicted using the distance rejection method\n",
        "correct_knn = 0 # count the number of examples correctly predicted using KNN\n",
        "results = [] # store the final prediction for each example\n",
        "\n",
        "# For each example in test data, check if the distance rejection method predicted it correctly\n",
        "# If yes, append the predicted label to results and increment the counter for correct predictions using the distance rejection method\n",
        "# If no, append the KNN predicted label to results\n",
        "for i in range(len(predictions_reject)):\n",
        "  if predictions_reject[i] == y_test[i]:\n",
        "    correct_distance += 1\n",
        "    results.append(predictions_reject[i])\n",
        "  else:\n",
        "    results.append(predict_knn[i])\n",
        "\n",
        "# Check the accuracy of the final predictions using KNN\n",
        "for i in range(len(results)):\n",
        "  if results[i] == y_test[i]:\n",
        "    correct_knn += 1\n",
        "\n",
        "# Calculate the global error rate as the percentage of misclassified examples\n",
        "global_error_rate = 100 - (correct_knn * 100) / len(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "2qpfflz8KEeP",
        "outputId": "f87eecc5-7e83-4b04-ba41-80cb3acaae06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Global error rate : 0.7407407407407476%\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 1st Stage Confusion Matrix (Distance Rejection)\n",
        "cm_reject = confusion_matrix(y_test, predictions_reject)\n",
        "cm_display = ConfusionMatrixDisplay(cm_reject)\n",
        "cm_display.plot(cmap='summer_r')\n",
        "plt.title(\"Distance rejection\")\n",
        "plt.xlabel(\"Predicted class\")\n",
        "plt.ylabel(\"True class\")\n",
        "\n",
        "# Waterfall confusion matrix (distance rejection + KNN)\n",
        "cm_cascade = confusion_matrix(y_test, results)\n",
        "cm_display = ConfusionMatrixDisplay(cm_cascade)\n",
        "cm_display.plot(cmap='summer')\n",
        "plt.title(\"Distance rejection + KNN\")\n",
        "plt.xlabel(\"Predicted class\")\n",
        "plt.ylabel(\"True class\")\n",
        "\n",
        "# Print of the global error rate\n",
        "print(\"Global error rate : \" + str(global_error_rate) + \"%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
